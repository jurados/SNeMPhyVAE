{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jurados/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Settings by default\n",
    "SIDEREAL_SCALE = 86400. / 86164.0905 # days per sidereal year\n",
    "TIME_WINDOW = 300\n",
    "TIME_PAD = 100\n",
    "ERROR_FLOOR = 0.01\n",
    "BANDS = ['v','r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_to_flux(light_curves):\n",
    "\n",
    "    for id_light_curve, light_curve in light_curves.groupby(by='oid'):\n",
    "        light_curves.loc[light_curve.index, 'flux'] = 10**(-0.4 * (light_curve['magpsf']+48.60))\n",
    "        light_curves.loc[light_curve.index, 'fluxerr'] = 10**(-0.4 * (light_curve['sigmapsf']+48.60))\n",
    "\n",
    "    light_curves = light_curves.drop(columns=['magpsf', 'sigmapsf'])\n",
    "\n",
    "    return light_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossmatch_object_alerce(alerce_lc: pd.DataFrame, object: pd.DataFrame) -> pd.DataFrame:\n",
    "    lightcurves = pd.merge(left=alerce_lc, right=object,\n",
    "                       on='oid')\n",
    "    return lightcurves\n",
    "\n",
    "def _determine_time_grid(ligth_curve):\n",
    "\n",
    "    time = ligth_curve['mjd'].to_numpy()\n",
    "    sidereal_time = time * SIDEREAL_SCALE\n",
    "\n",
    "    # Initial guess of the phase. Round everything to 0.1 days, and find the decimal\n",
    "    # that has the largest count.\n",
    "    mode, count = scipy.stats.mode(np.round(sidereal_time % 1 + 0.05, 1), keepdims=True)\n",
    "    guess_offset = mode[0] - 0.05\n",
    "\n",
    "    # Shift everything by the guessed offset\n",
    "    guess_shift_time = sidereal_time - guess_offset\n",
    "\n",
    "    # Do a proper estimate of the offset.\n",
    "    sidereal_offset = guess_offset + np.median((guess_shift_time + 0.5) % 1) - 0.5\n",
    "\n",
    "    # Shift everything by the final offset estimate.\n",
    "    shift_time = sidereal_time - sidereal_offset\n",
    "\n",
    "    # Selecting the five highest signal-to-noise observations\n",
    "    s2n = ligth_curve['flux'] / ligth_curve['fluxerr']\n",
    "    s2n_mask = np.argsort(s2n)[-5:]\n",
    "\n",
    "    cut_times = shift_time[s2n_mask]\n",
    "\n",
    "    max_time = np.round(np.median(cut_times))\n",
    "\n",
    "    # Convert back to a reference time in the original units. This reference time\n",
    "    # corresponds to the reference of the grid in sidereal time.\n",
    "    reference_time = ((max_time + sidereal_offset) / SIDEREAL_SCALE)\n",
    "\n",
    "    return reference_time\n",
    "\n",
    "def time_to_grid(time, reference_time):\n",
    "    return (time - reference_time) * SIDEREAL_SCALE\n",
    "\n",
    "def process_light_curve_parsnip(light_curve):\n",
    "    reference_time = _determine_time_grid(light_curve)\n",
    "\n",
    "    new_light_curve = light_curve.copy()\n",
    "\n",
    "    grid_times = time_to_grid(new_light_curve['mjd'], reference_time)\n",
    "    time_indices = np.round(grid_times).astype(int) + TIME_WINDOW // 2 # 300 days\n",
    "    time_mask = (\n",
    "        (time_indices >= -TIME_PAD)\n",
    "        & (time_indices < TIME_WINDOW + TIME_PAD)\n",
    "    )\n",
    "    new_light_curve['grid_time'] = grid_times\n",
    "    new_light_curve['time_index'] = time_indices\n",
    "    new_light_curve = new_light_curve[time_mask]\n",
    "\n",
    "    return new_light_curve\n",
    "\n",
    "def _get_data(light_curves):\n",
    "\n",
    "\n",
    "    redshifts = []\n",
    "    compare_data = []\n",
    "    compare_band_indices = []\n",
    "    print('Comenzo get_data')\n",
    "\n",
    "    # Build a grid for the input\n",
    "    # The first grid is created for saved the data\n",
    "    # The second grid is created for save the weights that will be used\n",
    "    # on the loss_function\n",
    "    try:\n",
    "        len_light_curves = len(light_curves.oid.unique())\n",
    "    except:\n",
    "        len_light_curves = len(light_curves)\n",
    "    #print('Length ligth_cruve:', len_light_curves)\n",
    "    grid_flux    = np.zeros((len_light_curves,len(BANDS),TIME_WINDOW))\n",
    "    #grid_flux    = np.zeros((len_light_curves,len(light_curves.fid.unique()),TIME_WINDOW))\n",
    "    print('Grid shape:',grid_flux.shape)\n",
    "    grid_weights = np.zeros_like(grid_flux)\n",
    "\n",
    "    for idx, light_curve in enumerate(light_curves):\n",
    "\n",
    "        redshifts.append(0.01)\n",
    "        #print(light_curve)\n",
    "        #print(type(light_curve))\n",
    "        #print(light_curve[list(light_curve.keys())[0]])\n",
    "        #light_curve = pd.DataFrame(torch.tensor(light_curve[list(light_curve.keys())[0]]))\n",
    "        light_curve = pd.DataFrame(light_curve)\n",
    "        #light_curve = light_curve[list(light_curve.keys())[0]]\n",
    "        #print('Se genero el respectivo DataFrame')\n",
    "        light_curve = light_curve[light_curve['fid'] <= 2]\n",
    "        # Mask observations outside the window\n",
    "        mask = (light_curve['time_index'] >= 0) & (light_curve['time_index'] < TIME_WINDOW)\n",
    "        light_curve = light_curve[mask]\n",
    "\n",
    "        # Calculate weights\n",
    "        weights = 1 / (light_curve['fluxerr']**2 + ERROR_FLOOR**2)\n",
    "\n",
    "        #print('fid:\\n', light_curve['fid'])\n",
    "        #print(light_curve['fid'].dtypes)\n",
    "        #print('fid:\\n', light_curve['fid']-1)\n",
    "        \n",
    "        \n",
    "        # Fill in the input arrays\n",
    "        #grid_flux[idx, 0 light_curve['time_index']] = light_curve['flux']\n",
    "        #print('Hay alguno mayor a 2:' (light_curve['fid'].astype(int) > 2).any())\n",
    "        #print('Hay alguno mayor a 2:' (light_curve['fid'].astype(int) > 2).any())\n",
    "        # Â¿NECESITO RESTARLE UNO A fid? Porque es un indice\n",
    "        grid_flux[idx, light_curve['fid'].astype(int)-1, light_curve['time_index']] = light_curve['flux']\n",
    "        #grid_weights[idx, 0, light_curve['time_index']] = ERROR_FLOOR**2 * weights\n",
    "        grid_weights[idx, light_curve['fid'].astype(int)-1, light_curve['time_index']] = ERROR_FLOOR**2 * weights\n",
    "\n",
    "        #print('Creo el grid')\n",
    "        obj_compare_data = torch.FloatTensor(np.vstack([\n",
    "            light_curve['grid_time'],\n",
    "            light_curve['flux'],\n",
    "            light_curve['fluxerr'], \n",
    "            weights,\n",
    "        ]))\n",
    "        compare_data.append(obj_compare_data.T)\n",
    "        compare_band_indices.append(torch.LongTensor(light_curve['fid'].to_numpy().copy()))\n",
    "\n",
    "    redshifts = np.array(redshifts)\n",
    "    extra_input_data = [redshifts]\n",
    "\n",
    "    #print(f\"Shape of extra_input_data elements: {[i.shape for i in extra_input_data]}\")\n",
    "    #print(f\"Shape of grid_flux: {grid_flux.shape}\")\n",
    "    #print(f\"Shape of grid_weights: {grid_weights.shape}\")\n",
    "\n",
    "    input_data = np.concatenate(\n",
    "            [i[:, None, None].repeat(TIME_WINDOW, axis=2) for i in extra_input_data]\n",
    "            + [grid_flux, grid_weights],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    input_data = torch.FloatTensor(input_data).to(device)\n",
    "    redshifts = torch.FloatTensor(redshifts).to(device)\n",
    "\n",
    "    # Pad all of the compare data to have the same shape.\n",
    "    compare_data = nn.utils.rnn.pad_sequence(compare_data, batch_first=True)\n",
    "    compare_data = compare_data.permute(0, 2, 1)\n",
    "    compare_band_indices = nn.utils.rnn.pad_sequence(compare_band_indices,batch_first=True)\n",
    "    \n",
    "    compare_data = compare_data.to(device)\n",
    "    compare_band_indices = compare_band_indices.to(device)\n",
    "\n",
    "    data = {\n",
    "        'input_data': input_data,\n",
    "        'compare_data': compare_data,\n",
    "        'redshift': redshifts,\n",
    "        'fid': compare_band_indices,\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_curve(light_curve, oid:any = None):\n",
    "\n",
    "    time = light_curve['mjd'].to_numpy()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    try:\n",
    "      mag  = light_curve['magpsf'].to_numpy()\n",
    "      ax.plot(time,mag,'o')\n",
    "      ax.set_ylim(ax.get_ylim()[::-1])\n",
    "      ax.set_ylabel('Apparent magnitude')\n",
    "    except:\n",
    "      flux = light_curve['flux'].to_numpy()\n",
    "      ax.plot(time,flux,'o')\n",
    "      ax.set_ylabel(r'Flux erg sâ1 cmâ2 Hzâ1')\n",
    "    ax.set_xlabel('MJD')\n",
    "\n",
    "\n",
    "    if oid != None:\n",
    "        ax.set_title(f'oid: {oid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                oid source_id      firstmjd   Av_MW true_label\n",
      "0      ZTF24aanbjel   2024iqx  60440.299120  0.0287         SN\n",
      "1      ZTF24aamkufg   2024igh  60437.289560  0.0261       SNIa\n",
      "2      ZTF24aajnwwr   2024hqr  60429.209850  0.0509       SNIa\n",
      "3      ZTF18aaeopbs   2024glo  60407.202211  0.1403       SNIa\n",
      "4      ZTF24aamtsgz   2024ipf  60438.397951  0.2484       SNIa\n",
      "...             ...       ...           ...     ...        ...\n",
      "10868  ZTF19aamqjsh   2016cda  58558.284549  0.0447       SNIa\n",
      "10869  ZTF18aarefgc   2016bey  60315.469572  0.0355       SNIa\n",
      "10870  ZTF18aajleyh   2016ayf  58276.285139  0.0533       SNIa\n",
      "10871  ZTF22abntkbk    2016nx  59870.374664  0.5834       SNIa\n",
      "10872  ZTF19acetbxm     2016Z  58770.438901  0.1020       SNIa\n",
      "\n",
      "[10873 rows x 5 columns]\n",
      "\n",
      "Number of Different Objects in object_table: 10870\n"
     ]
    }
   ],
   "source": [
    "object_table = pd.read_pickle('~/Supernovae_DeepLearning/object_ZTF_ALeRCE_19052024.pkl')\n",
    "print(object_table)\n",
    "print('\\nNumber of Different Objects in object_table:', len(object_table.oid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  oid               candid         rfid           mjd  fid  \\\n",
      "0        ZTF19abgpgyp  1515523874715015006  681120247.0  59269.523877    2   \n",
      "1        ZTF19abgpgyp  1499511354715015014          NaN  59253.511354    2   \n",
      "2        ZTF19abgpgyp  1502430264715015014          NaN  59256.430266    2   \n",
      "3        ZTF19abgpgyp  1510536184715015009          NaN  59264.536181    2   \n",
      "4        ZTF18abjswhy  1515520891415015005  685120214.0  59269.520891    2   \n",
      "...               ...                  ...          ...           ...  ...   \n",
      "4546324  ZTF19ablwbut  1508538592115015009          NaN  59262.538599    1   \n",
      "4546325  ZTF19ablwbut  1511512652115015011          NaN  59265.512651    1   \n",
      "4546326  ZTF19ablwbut  1513537042115015020          NaN  59267.537049    1   \n",
      "4546327  ZTF19ablwbut  1515495032115015010          NaN  59269.495035    1   \n",
      "4546328  ZTF18aagrdtj  1515523411415010004  680120214.0  59269.523414    2   \n",
      "\n",
      "            magpsf  sigmapsf  \n",
      "0        20.385720  0.211641  \n",
      "1        20.678400  0.258971  \n",
      "2        20.652500  0.269586  \n",
      "3        20.663600  0.299923  \n",
      "4        16.079460  0.030863  \n",
      "...            ...       ...  \n",
      "4546324  17.079200  0.062217  \n",
      "4546325  17.125100  0.057529  \n",
      "4546326  17.073800  0.073881  \n",
      "4546327  17.232900  0.056399  \n",
      "4546328  18.910412  0.079225  \n",
      "\n",
      "[4546329 rows x 7 columns]\n",
      "\n",
      "Number of Different Objects in lightcurves_alercextns: 69519\n"
     ]
    }
   ],
   "source": [
    "lightcurves_alercextns = pd.read_pickle('/home/jurados/Supernovae_DeepLearning/data/lightcurves/lcs_transients_20240517.pkl')\n",
    "print(lightcurves_alercextns)\n",
    "print('\\nNumber of Different Objects in lightcurves_alercextns:', len(lightcurves_alercextns.oid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 oid               candid         rfid           mjd  fid  \\\n",
      "0       ZTF19abgpgyp  1515523874715015006  681120247.0  59269.523877    2   \n",
      "1       ZTF19abgpgyp  1499511354715015014          NaN  59253.511354    2   \n",
      "2       ZTF19abgpgyp  1502430264715015014          NaN  59256.430266    2   \n",
      "3       ZTF19abgpgyp  1510536184715015009          NaN  59264.536181    2   \n",
      "4       ZTF19aatubsj  1515535253915015003  634120239.0  59269.535255    2   \n",
      "...              ...                  ...          ...           ...  ...   \n",
      "311883  ZTF18aavtvxx  1515516622515010002  826120225.0  59269.516620    2   \n",
      "311884  ZTF20acgyjbh  1515521513815015012  483120238.0  59269.521516    2   \n",
      "311885  ZTF20acgyjbh  1513527463815015004          NaN  59267.527465    1   \n",
      "311886  ZTF20acgyjbh  1515466313815015003          NaN  59269.466319    1   \n",
      "311887  ZTF19acbwmqd  1515523414215015020  680120242.0  59269.523414    2   \n",
      "\n",
      "           magpsf  sigmapsf source_id      firstmjd   Av_MW true_label  \n",
      "0       20.385720  0.211641   2019lkw  58681.194086  0.0608       SNII  \n",
      "1       20.678400  0.258971   2019lkw  58681.194086  0.0608       SNII  \n",
      "2       20.652500  0.269586   2019lkw  58681.194086  0.0608       SNII  \n",
      "3       20.663600  0.299923   2019lkw  58681.194086  0.0608       SNII  \n",
      "4       20.251050  0.161910   2019fdr  58605.400428  0.1393       SLSN  \n",
      "...           ...       ...       ...           ...     ...        ...  \n",
      "311883  18.331059  0.091234    2018mc  58255.410312  0.0965      SNIIb  \n",
      "311884  19.333435  0.109986   2020vck  59128.149931  0.3555       SNII  \n",
      "311885  20.057800  0.273645   2020vck  59128.149931  0.3555       SNII  \n",
      "311886  20.268000  0.402365   2020vck  59128.149931  0.3555       SNII  \n",
      "311887  18.667158  0.067825   2019rra  58758.143171  0.0608       SNII  \n",
      "\n",
      "[311888 rows x 11 columns]\n",
      "\n",
      "Number of Different Objects in lightcurves (Crossmatch): 8042\n"
     ]
    }
   ],
   "source": [
    "# Here I realized a crossmatch between all lightcurves_alercextns and\n",
    "# the object table\n",
    "lightcurves = crossmatch_object_alerce(lightcurves_alercextns, object_table)\n",
    "print(lightcurves)\n",
    "print('\\nNumber of Different Objects in lightcurves (Crossmatch):', len(lightcurves.oid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(test_size=.2, random_state=0)\n",
    "train_inds, test_inds = next(splitter.split(lightcurves, groups=lightcurves['oid']))\n",
    "train_data = lightcurves.iloc[train_inds]\n",
    "test_data  = lightcurves.iloc[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6433, 1609)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.oid.unique()), len(test_data.oid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The oid of transients with maximum length is: ZTF18aavtvxx\n",
      "The maximum length of observation is: 1400\n"
     ]
    }
   ],
   "source": [
    "print('The oid of transients with maximum length is:', train_data.groupby(by='oid')['mjd'].size().idxmax())\n",
    "print('The maximum length of observation is:', train_data.groupby(by='oid')['mjd'].size().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['oid','mjd','magpsf','sigmapsf','fid']]\n",
    "test_data = test_data[['oid','mjd','magpsf','sigmapsf','fid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>mjd</th>\n",
       "      <th>magpsf</th>\n",
       "      <th>sigmapsf</th>\n",
       "      <th>fid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59270.233553</td>\n",
       "      <td>17.273174</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59270.295313</td>\n",
       "      <td>17.398106</td>\n",
       "      <td>0.066342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59271.225451</td>\n",
       "      <td>17.224977</td>\n",
       "      <td>0.036484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59271.258333</td>\n",
       "      <td>17.460032</td>\n",
       "      <td>0.053383</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59272.170428</td>\n",
       "      <td>17.278603</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38841</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59265.212002</td>\n",
       "      <td>17.426886</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38869</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59266.133750</td>\n",
       "      <td>17.260433</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38870</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59266.212928</td>\n",
       "      <td>17.376047</td>\n",
       "      <td>0.041131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38900</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59267.174965</td>\n",
       "      <td>17.450434</td>\n",
       "      <td>0.042498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38903</th>\n",
       "      <td>ZTF20acphdcg</td>\n",
       "      <td>59267.253657</td>\n",
       "      <td>17.282661</td>\n",
       "      <td>0.050623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                oid           mjd     magpsf  sigmapsf  fid\n",
       "9      ZTF20acphdcg  59270.233553  17.273174  0.051715    1\n",
       "13     ZTF20acphdcg  59270.295313  17.398106  0.066342    2\n",
       "36     ZTF20acphdcg  59271.225451  17.224977  0.036484    1\n",
       "39     ZTF20acphdcg  59271.258333  17.460032  0.053383    2\n",
       "49     ZTF20acphdcg  59272.170428  17.278603  0.047779    1\n",
       "...             ...           ...        ...       ...  ...\n",
       "38841  ZTF20acphdcg  59265.212002  17.426886  0.042634    2\n",
       "38869  ZTF20acphdcg  59266.133750  17.260433  0.055329    1\n",
       "38870  ZTF20acphdcg  59266.212928  17.376047  0.041131    2\n",
       "38900  ZTF20acphdcg  59267.174965  17.450434  0.042498    2\n",
       "38903  ZTF20acphdcg  59267.253657  17.282661  0.050623    1\n",
       "\n",
       "[327 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_light_curve = train_data[train_data.oid == train_data.oid.unique()[3]]\n",
    "one_light_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_light_curve(one_light_curve, one_light_curve.oid.unique()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next Syntethic model is based on the papers of [Olivares et al. 2010](https://ui.adsabs.harvard.edu/abs/2010ApJ...715..833O/abstract).\n",
    "\n",
    "This synthetic model created light-curves based on the next functions:\n",
    "\n",
    "$$ f_{\\text{DF}} = \\frac{-a_0}{1+\\exp\\left( (t - t_{\\text{PT}})\\right) / w_0}$$\n",
    "$$ l(t) = p_o(t-t_{\\text{PT}}) + m_0$$\n",
    "$$ g(t) = -P e^{\\left(\\frac{t-Q}{R}\\right)^{2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticLigthCurve:\n",
    "    def __init__(self,tpt,a0,w0,p0,m0,P,Q,R):\n",
    "        self.a0 = a0\n",
    "        self.w0 = w0\n",
    "        self.tpt = tpt\n",
    "        self.p0 = p0\n",
    "        self.m0 = m0\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.R = R\n",
    "\n",
    "    def olivares(self,t):\n",
    "        f_fd = -self.a0/(1+np.exp((t-self.tpt)/self.w0))\n",
    "        f_ld = self.p0*(t-self.tpt)+self.m0\n",
    "        f_gs =  -self.P * np.exp(-((t-self.Q)/self.R)**2)\n",
    "        f = f_fd + f_ld + f_gs\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parÃ¡metros iniciales\n",
    "p0_v = [91.026,1.744,3.602,0.008,14.482,1.675,102.148,-15.984] # tpt, a0, w0, p0_v, m0, P, Q, R\n",
    "p0_r = [88.948,1.584,4.485,0.005,13.759,1.528,101.390,-17.934] # tpt, a0, w0, p0_v, m0, P, Q, R\n",
    "increase_factor = [1, 1, 0.01, 0, 0.01, 0.01, 0.01, 0.01]\n",
    "\n",
    "N = 1000\n",
    "time_length = 300 # days\n",
    "\n",
    "oid = []\n",
    "mjd = []\n",
    "mag_v = []\n",
    "mag_r = []\n",
    "\n",
    "# GeneraciÃ³n de los datos sintÃ©ticos\n",
    "for n in range(N):\n",
    "    increase_random = np.random.random()\n",
    "    time = np.linspace(50, 150, 50)\n",
    "    \n",
    "    po_v = [p0_v[i] + increase_factor[i] * increase_random for i in range(len(p0_v))]\n",
    "    po_r = [p0_r[i] + increase_factor[i] * increase_random for i in range(len(p0_r))]\n",
    "    \n",
    "    synthetic_lc_v = SyntheticLigthCurve(po_v[0], po_v[1], po_v[2], po_v[3], po_v[4], po_v[5], po_v[6], po_v[7])\n",
    "    synthetic_lc_r = SyntheticLigthCurve(po_r[0], po_r[1], po_r[2], po_r[3], po_r[4], po_r[5], po_r[6], po_r[7])\n",
    "    \n",
    "    f_v = synthetic_lc_v.olivares(time)\n",
    "    f_r = synthetic_lc_r.olivares(time)\n",
    "    \n",
    "    mjd.append(np.array(time))\n",
    "    mag_v.append(np.array(f_v))\n",
    "    mag_r.append(np.array(f_r))\n",
    "\n",
    "# Crear una lista vacÃ­a para almacenar los datos\n",
    "train_data_synthetic = []\n",
    "test_data_synthetic  = []\n",
    "\n",
    "# Iterar sobre cada conjunto de tiempo y brillo\n",
    "for i in range(len(mjd)):\n",
    "    time_set = mjd[i]\n",
    "    brightness_set_v = mag_v[i]\n",
    "    brightness_set_r = mag_r[i]\n",
    "    code = 'ZTF' + str(i + 1)  # CÃ³digo de pertenencia (del 1 al N)\n",
    "    \n",
    "    for time, brightness_v, brightness_r in zip(time_set, brightness_set_v, brightness_set_r):\n",
    "        if i + 1 <= int(N * 0.8):  # 80% para entrenamiento\n",
    "            # AÃ±adir observaciones de filtro v (fid = 1)\n",
    "            train_data_synthetic.append([code, time, brightness_v, 1])\n",
    "            # AÃ±adir observaciones de filtro r (fid = 2)\n",
    "            train_data_synthetic.append([code, time, brightness_r, 2])\n",
    "        else:  # 20% para prueba\n",
    "            # AÃ±adir observaciones de filtro v (fid = 1)\n",
    "            test_data_synthetic.append([code, time, brightness_v, 1])\n",
    "            # AÃ±adir observaciones de filtro r (fid = 2)\n",
    "            test_data_synthetic.append([code, time, brightness_r, 2])\n",
    "\n",
    "# Crear los DataFrames\n",
    "train_data_synthetic = pd.DataFrame(train_data_synthetic, columns=['oid', 'mjd', 'magpsf', 'fid'])\n",
    "test_data_synthetic = pd.DataFrame(test_data_synthetic, columns=['oid', 'mjd', 'magpsf', 'fid'])\n",
    "\n",
    "# AÃ±adir una columna para 'sigmapsf'\n",
    "train_data_synthetic['sigmapsf'] = 0.001\n",
    "test_data_synthetic['sigmapsf'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oid_idx = 0\n",
    "plot_light_curve(train_data_synthetic[train_data_synthetic.oid == train_data_synthetic.oid.unique()[oid_idx]], oid=train_data_synthetic.oid.unique()[oid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_synthetic = mag_to_flux(train_data_synthetic)\n",
    "test_data_synthetic  = mag_to_flux(test_data_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fid</th>\n",
       "      <th>flux</th>\n",
       "      <th>fluxerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZTF1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.902192e-25</td>\n",
       "      <td>3.627438e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZTF1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.319067e-24</td>\n",
       "      <td>3.627438e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZTF1</td>\n",
       "      <td>52.040816</td>\n",
       "      <td>1</td>\n",
       "      <td>8.769586e-25</td>\n",
       "      <td>3.627438e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZTF1</td>\n",
       "      <td>52.040816</td>\n",
       "      <td>2</td>\n",
       "      <td>1.306932e-24</td>\n",
       "      <td>3.627438e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTF1</td>\n",
       "      <td>54.081633</td>\n",
       "      <td>1</td>\n",
       "      <td>8.639298e-25</td>\n",
       "      <td>3.627438e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    oid        mjd  fid          flux       fluxerr\n",
       "0  ZTF1  50.000000    1  8.902192e-25  3.627438e-20\n",
       "1  ZTF1  50.000000    2  1.319067e-24  3.627438e-20\n",
       "2  ZTF1  52.040816    1  8.769586e-25  3.627438e-20\n",
       "3  ZTF1  52.040816    2  1.306932e-24  3.627438e-20\n",
       "4  ZTF1  54.081633    1  8.639298e-25  3.627438e-20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_synthetic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mag_to_flux(train_data)\n",
    "test_data = mag_to_flux(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fid</th>\n",
       "      <th>flux</th>\n",
       "      <th>fluxerr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZTF19abgpgyp</td>\n",
       "      <td>59269.523877</td>\n",
       "      <td>2</td>\n",
       "      <td>2.545142e-28</td>\n",
       "      <td>2.987744e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZTF19abgpgyp</td>\n",
       "      <td>59253.511354</td>\n",
       "      <td>2</td>\n",
       "      <td>1.943748e-28</td>\n",
       "      <td>2.860300e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZTF19abgpgyp</td>\n",
       "      <td>59256.430266</td>\n",
       "      <td>2</td>\n",
       "      <td>1.990673e-28</td>\n",
       "      <td>2.832472e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZTF19abgpgyp</td>\n",
       "      <td>59264.536181</td>\n",
       "      <td>2</td>\n",
       "      <td>1.970425e-28</td>\n",
       "      <td>2.754424e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTF19aatubsj</td>\n",
       "      <td>59269.535255</td>\n",
       "      <td>2</td>\n",
       "      <td>2.881244e-28</td>\n",
       "      <td>3.127780e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            oid           mjd  fid          flux       fluxerr\n",
       "0  ZTF19abgpgyp  59269.523877    2  2.545142e-28  2.987744e-20\n",
       "1  ZTF19abgpgyp  59253.511354    2  1.943748e-28  2.860300e-20\n",
       "2  ZTF19abgpgyp  59256.430266    2  1.990673e-28  2.832472e-20\n",
       "3  ZTF19abgpgyp  59264.536181    2  1.970425e-28  2.754424e-20\n",
       "4  ZTF19aatubsj  59269.535255    2  2.881244e-28  3.127780e-20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oid_idx = 0\n",
    "plot_light_curve(train_data_synthetic[train_data_synthetic.oid == train_data_synthetic.oid.unique()[oid_idx]], oid=train_data_synthetic.oid.unique()[oid_idx])\n",
    "plot_light_curve(train_data[train_data.oid == train_data.oid.unique()[oid_idx]], oid=train_data.oid.unique()[oid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    oid        mjd  fid          flux       fluxerr\n",
      "0  ZTF1  50.000000    1  8.902192e-25  3.627438e-20\n",
      "1  ZTF1  50.000000    2  1.319067e-24  3.627438e-20\n",
      "2  ZTF1  52.040816    1  8.769586e-25  3.627438e-20\n",
      "3  ZTF1  52.040816    2  1.306932e-24  3.627438e-20\n",
      "4  ZTF1  54.081633    1  8.639298e-25  3.627438e-20\n",
      "\n",
      "Shape train_data_synthethic: (80000, 5)\n",
      "Length train_data_synthethic: 80000\n",
      "\n",
      "      oid        mjd  fid          flux       fluxerr\n",
      "0  ZTF801  50.000000    1  4.874237e-25  3.627438e-20\n",
      "1  ZTF801  50.000000    2  7.235767e-25  3.627438e-20\n",
      "2  ZTF801  52.040816    1  4.801642e-25  3.627438e-20\n",
      "3  ZTF801  52.040816    2  7.169419e-25  3.627438e-20\n",
      "4  ZTF801  54.081633    1  4.730323e-25  3.627438e-20\n",
      "\n",
      "Shape test_data_synthethic: (20000, 5)\n",
      "Length test_data_synthethic: 20000\n"
     ]
    }
   ],
   "source": [
    "print(train_data_synthetic.head())\n",
    "print('\\nShape train_data_synthethic:', train_data_synthetic.shape)\n",
    "print('Length train_data_synthethic:', len(train_data_synthetic))\n",
    "print()\n",
    "print(test_data_synthetic.head())\n",
    "print('\\nShape test_data_synthethic:', test_data_synthetic.shape)\n",
    "print('Length test_data_synthethic:', len(test_data_synthetic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_light_curves(light_curves):\n",
    "    \"\"\" Create a new data set adding the grid_time and\n",
    "    time_index columns\n",
    "    \"\"\"\n",
    "\n",
    "    new_light_curves = pd.DataFrame()\n",
    "    for id_group, group in light_curves.groupby('oid'):\n",
    "        light_curve_processed = process_light_curve_parsnip(group)\n",
    "        new_light_curves = pd.concat([new_light_curves, light_curve_processed])\n",
    "\n",
    "    return new_light_curves\n",
    "\n",
    "\n",
    "train_data_synthetic = new_light_curves(train_data_synthetic)\n",
    "test_data_synthetic  = new_light_curves(test_data_synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = new_light_curves(train_data)\n",
    "test_data  = new_light_curves(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    oid        mjd  fid          flux       fluxerr  grid_time  time_index\n",
      "0  ZTF1  50.000000    1  8.902192e-25  3.627438e-20  -4.124136         146\n",
      "1  ZTF1  50.000000    2  1.319067e-24  3.627438e-20  -4.124136         146\n",
      "2  ZTF1  52.040816    1  8.769586e-25  3.627438e-20  -2.077733         148\n",
      "3  ZTF1  52.040816    2  1.306932e-24  3.627438e-20  -2.077733         148\n",
      "4  ZTF1  54.081633    1  8.639298e-25  3.627438e-20  -0.031329         150\n",
      "\n",
      "Shape train_data_synthethic: (80000, 7)\n",
      "Length train_data_synthethic: 80000\n",
      "\n",
      "           oid        mjd  fid          flux       fluxerr  grid_time  \\\n",
      "19900  ZTF1000  50.000000    1  7.067790e-25  3.627438e-20  -4.124136   \n",
      "19901  ZTF1000  50.000000    2  1.048002e-24  3.627438e-20  -4.124136   \n",
      "19902  ZTF1000  52.040816    1  6.962514e-25  3.627438e-20  -2.077733   \n",
      "19903  ZTF1000  52.040816    2  1.038371e-24  3.627438e-20  -2.077733   \n",
      "19904  ZTF1000  54.081633    1  6.859082e-25  3.627438e-20  -0.031329   \n",
      "\n",
      "       time_index  \n",
      "19900         146  \n",
      "19901         146  \n",
      "19902         148  \n",
      "19903         148  \n",
      "19904         150  \n",
      "\n",
      "Shape test_data_synthethic: (20000, 7)\n",
      "Length test_data_synthethic: 20000\n"
     ]
    }
   ],
   "source": [
    "print(train_data_synthetic.head())\n",
    "print('\\nShape train_data_synthethic:', train_data_synthetic.shape)\n",
    "print('Length train_data_synthethic:', len(train_data_synthetic))\n",
    "print()\n",
    "print(test_data_synthetic.head())\n",
    "print('\\nShape test_data_synthethic:', test_data_synthetic.shape)\n",
    "print('Length test_data_synthethic:', len(test_data_synthetic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightCurveDataset():\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        # Agrupar por 'oid' y almacenar los grupos\n",
    "        self.groups = dataframe.groupby('oid')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener el 'oid' por Ã­ndice (esto devuelve una tupla: (oid, dataframe))\n",
    "        oid, group = list(self.groups)[idx]\n",
    "\n",
    "        # Convertir las columnas 'tiempo' y 'mag' en listas\n",
    "        #mjd = torch.tensor(group['mjd'].values, dtype=torch.float32).to(device)\n",
    "        #magpsf = torch.tensor(group['magpsf'].values, dtype=torch.float32).to(device)\n",
    "        #sigmapsf = torch.tensor(group['sigmapsf'].values, dtype=torch.float32).to(device)\n",
    "        #grid_time = torch.tensor(group['grid_time'].values, dtype=torch.float32).to(device)\n",
    "        #time_index = torch.tensor(group['time_index'].values, dtype=torch.float32).to(device)\n",
    "\n",
    "        mjd = group['mjd'].to_numpy()\n",
    "        flux = group['flux'].to_numpy()\n",
    "        fluxerr = group['fluxerr'].to_numpy()\n",
    "        fid = group['fid'].to_numpy()\n",
    "        grid_time = group['grid_time'].to_numpy()\n",
    "        time_index = group['time_index'].to_numpy()\n",
    "\n",
    "\n",
    "        # Retornar un diccionario en el formato deseado\n",
    "        # light_curve_dict = {\n",
    "        #     oid: {\n",
    "        #         'mjd': mjd,\n",
    "        #         'flux': flux,\n",
    "        #         'fluxerr': fluxerr,\n",
    "        #         'grid_time': grid_time,\n",
    "        #         'time_index': time_index\n",
    "        #     }\n",
    "        # }\n",
    "\n",
    "        light_curve_dict = {\n",
    "          'mjd': mjd,\n",
    "          'fid': fid,\n",
    "          'flux': flux,\n",
    "          'fluxerr': fluxerr,\n",
    "          'grid_time': grid_time,\n",
    "          'time_index': time_index\n",
    "        }\n",
    "\n",
    "        # light_curve_dict = {\n",
    "        #   'mjd': torch.tensor(mjd, dtype=torch.float32).to(device),\n",
    "        #   'flux': torch.tensor(flux, dtype=torch.float32).to(device),\n",
    "        #   'fluxerr': torch.tensor(fluxerr, dtype=torch.float32).to(device),\n",
    "        #   'grid_time': torch.tensor(grid_time, dtype=torch.torch.uint32).to(device),\n",
    "        #   'time_index': torch.tensor(time_index, dtype=torch.torch.uint32).to(device)\n",
    "        # }\n",
    "\n",
    "        return light_curve_dict\n",
    "\n",
    "# Instancia el dataset personalizado\n",
    "train_pandas_dataset = LightCurveDataset(train_data)\n",
    "train_pandas_dataset_synthetic = LightCurveDataset(train_data_synthetic)\n",
    "test_pandas_dataset = LightCurveDataset(test_data)\n",
    "test_pandas_dataset_synthetic = LightCurveDataset(test_data_synthetic)\n",
    "\n",
    "# Crear el DataLoader\n",
    "train_loader = DataLoader(train_pandas_dataset, batch_size=64, collate_fn=list, shuffle=True)\n",
    "test_loader = DataLoader(test_pandas_dataset, batch_size=64, collate_fn=list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(type(batch))  # Verifica el tipo de batch\n",
    "    print(batch[0]['time_index'])\n",
    "    print(_get_data(batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV0(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, latent_size, device):\n",
    "\n",
    "        self.device = device\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size, out_features=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_dim, out_features=latent_size),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "        # latent mean and variance\n",
    "        # AcÃ¡ tenia un dos en\n",
    "        #mu_size, logvar_size = 3, 3\n",
    "        self.encode_mean_layer = nn.Linear(in_features=latent_size, out_features=2)\n",
    "        self.encode_logvar_layer = nn.Linear(in_features=latent_size, out_features=2)\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=2, out_features=latent_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=latent_size, out_features=hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_dim, out_features=input_size),\n",
    "            )\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def encode(self, x):\n",
    "        print('Shape pre-encoder', x.shape)\n",
    "        x = x.permute(0,2,1)\n",
    "        print('second Shape pre-encoder', x.shape)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        print('Entro al Encoder')\n",
    "        print(x.shape)\n",
    "        mean, logvar = self.encode_mean_layer(x), self.encode_logvar_layer(x)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterization(self, mean, logvar):\n",
    "        print('Esta parametrizando al Encoder')\n",
    "        # Var(x) = std**2 -> 0.5*ln(Var(x)) = ln(std)\n",
    "        # std = exp(0.5*ln(Var(x)))\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mean + eps*std\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        print('Entro al DeEncoder')\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        print('Melo el forward')\n",
    "        return x_hat, mean, logvar\n",
    "\n",
    "    def obtain_results(self, light_curves):\n",
    "\n",
    "        data = _get_data(light_curves)\n",
    "        print('Paso el Get data')\n",
    "\n",
    "        # Encode the light_curves\n",
    "        encoding_mu, encoding_logvar = self.encode(data['input_data'])\n",
    "        #print(encoding_mu)\n",
    "        #print(encoding_logvar)\n",
    "\n",
    "        time = data['compare_data'][:,0]\n",
    "        obs_flux = data['compare_data'][:, 1]\n",
    "        obs_fluxerr = data['compare_data'][:, 2]\n",
    "        obs_weight = data['compare_data'][:, 3]\n",
    "\n",
    "        results ={\n",
    "            'redshift': data['redshift'],\n",
    "            'time': time,\n",
    "            'obs_flux': obs_flux,\n",
    "            'obs_fluxerr': obs_fluxerr,\n",
    "            'obs_weight': obs_weight,\n",
    "            'encoding_mu': encoding_mu,\n",
    "            'encoding_logvar': encoding_logvar,\n",
    "        }\n",
    "\n",
    "        #results = {k:v.detach().cpu().numpy() for k,v in results.items()}\n",
    "        #results = {k:v.detach().cpu().numpy() for k,v in results.items()}\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    \"\"\" This model will use Conv1d to encode the NN\n",
    "    The Output Size using Conv1d in Pytorch could be calculated using:\n",
    "\n",
    "    L_out = [Lin + 2 x padding - dilation x (kernel_size - 1) - 1] / stride + 1\n",
    "\n",
    "    Also this modle will use ConvTransposed1d to decode the NN\n",
    "    The Ouput size using ConvTransposed1d in PyTorch could be calculated using:\n",
    "\n",
    "    L_out=(Lin-1)xstride-2xpadding+dilationx(kernel_size-1)+output_padding+1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, latent_size: int, batch_size:int, device: str, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=16, kernel_size=3, dilation=1, padding=2*1),  # Input size [batch_size, input_size = 3, 300] Output_size = [batch_size, 16, 302]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, dilation=1, padding=2*1),  # Input size [batch_size, input_size = 16, 302] Output_size = [batch_size, 32, 304]\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, dilation=1, padding=2*1), # Input size [batch_size, input_size = 32, 304] Output_size = [batch_size, 64, 306]\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=batch_size*306, out_features=64)\n",
    "\n",
    "        # Linear layers for encoding mean and logvar\n",
    "        self.encode_mean = nn.Linear(in_features=64, out_features=latent_size)\n",
    "        self.encode_logvar = nn.Linear(in_features=64, out_features=latent_size)\n",
    "\n",
    "        # Decoder input layer\n",
    "        self.decoder_input = nn.Linear(in_features=latent_size, out_features=64)\n",
    "\n",
    "        # Decoder with transposed convolutions (ConvTranspose1d)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=32, kernel_size=3, padding=2*1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=32, out_channels=16, kernel_size=3, padding=2*1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=16, out_channels=3, kernel_size=3, padding=2*1)  # Output size [batch_size, 3, input_size]\n",
    "        )\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def encode(self, x):\n",
    "        print('Shape pre-encoder', x.shape)\n",
    "        x = self.encoder(x)\n",
    "        print('Shape Encoder:',x.shape)\n",
    "        x = x.view(64, -1) # Flatten the output, keeping batch dimension\n",
    "        #print('Shape after flattening:', x.shape)\n",
    "        x = self.linear(x)\n",
    "        mu, log_var = self.encode_mean(x), self.encode_logvar(x)\n",
    "        print('Shape mu:',mu.shape)\n",
    "        print('Shape log_var:',log_var.shape)\n",
    "        return mu, log_var\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        result = self.decoder_input(z)\n",
    "        result = self.decoder(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, input: torch.Tensor, **kwargs) -> list:\n",
    "        print('Shape input:',input.shape)\n",
    "        mu, log_var = self.encode(input)\n",
    "        print('Shape mu:',mu.shape)\n",
    "        print('Shape log_var:',log_var.shape)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return [self.decode(z), input, mu, log_var]\n",
    "\n",
    "    def obtain_results(self, light_curves):\n",
    "\n",
    "        data = _get_data(light_curves)\n",
    "        print('Paso el Get data')\n",
    "\n",
    "        # Encode the light_curves\n",
    "        encoding_mu, encoding_logvar = self.encode(data['input_data'])\n",
    "        #print(encoding_mu)\n",
    "        #print(encoding_logvar)\n",
    "\n",
    "        time = data['compare_data'][:,0]\n",
    "        obs_flux = data['compare_data'][:, 1]\n",
    "        obs_fluxerr = data['compare_data'][:, 2]\n",
    "        obs_weight = data['compare_data'][:, 3]\n",
    "\n",
    "        results ={\n",
    "            'redshift': data['redshift'],\n",
    "            'time': time,\n",
    "            'obs_flux': obs_flux,\n",
    "            'obs_fluxerr': obs_fluxerr,\n",
    "            'obs_weight': obs_weight,\n",
    "            'fid': data['fid'],\n",
    "            'encoding_mu': encoding_mu,\n",
    "            'encoding_logvar': encoding_logvar,\n",
    "        }\n",
    "\n",
    "        #results = {k:v.detach().cpu().numpy() for k,v in results.items()}\n",
    "        #results = {k:v.detach().cpu().numpy() for k,v in results.items()}\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5 # input_size = 2 * N_bands + 1 -> 2: flux and error 1 for redshift.\n",
    "h_dim = 200\n",
    "z_dim = 20\n",
    "num_epoch = 1\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "\n",
    "#model = ModelV0(input_size=input_size, hidden_dim=h_dim, latent_size=z_dim, device=device)\n",
    "model = ModelV1(input_size = input_size, latent_size = z_dim, batch_size=batch_size, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_pandas_dataset, batch_size=batch_size, collate_fn=list, shuffle=True)\n",
    "train_loader_synthetic = DataLoader(train_pandas_dataset_synthetic, batch_size=batch_size, collate_fn=list, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_pandas_dataset, batch_size=batch_size, collate_fn=list, shuffle=True)\n",
    "test_loader_synthetic = DataLoader(test_pandas_dataset_synthetic, batch_size=batch_size, collate_fn=list, shuffle=False)\n",
    "\n",
    "#train_loader = DataLoader(train_pandas_dataset, batch_size=batch_size, collate_fn=list, shuffle=True)\n",
    "#test_loader = DataLoader(test_pandas_dataset, batch_size=batch_size, collate_fn=list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ModelV1                                  --\n",
       "ââSequential: 1-1                        --\n",
       "â    ââConv1d: 2-1                       256\n",
       "â    ââReLU: 2-2                         --\n",
       "â    ââConv1d: 2-3                       1,568\n",
       "â    ââReLU: 2-4                         --\n",
       "â    ââConv1d: 2-5                       6,208\n",
       "â    ââReLU: 2-6                         --\n",
       "ââLinear: 1-2                            626,752\n",
       "ââLinear: 1-3                            1,300\n",
       "ââLinear: 1-4                            1,300\n",
       "ââLinear: 1-5                            1,344\n",
       "ââSequential: 1-6                        --\n",
       "â    ââConvTranspose1d: 2-7              6,176\n",
       "â    ââReLU: 2-8                         --\n",
       "â    ââConvTranspose1d: 2-9              1,552\n",
       "â    ââReLU: 2-10                        --\n",
       "â    ââConvTranspose1d: 2-11             147\n",
       "=================================================================\n",
       "Total params: 646,603\n",
       "Trainable params: 646,603\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(results):\n",
    "\n",
    "#     print('X_reconstructed:\\nType:',type(X_reconstructed),\\\n",
    "#           '\\nShape:',X_reconstructed.shape)\n",
    "#     print('X_weights:\\nType',type(X_weights),\\\n",
    "#           '\\nShape:',X_weights.shape)\n",
    "      nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
    "      kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
    "                      - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
    "                      - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n",
    "\n",
    "      nll = torch.sum(nll)\n",
    "      #print(nll)\n",
    "      kl_div = torch.sum(kld)\n",
    "      #print(kl_div)\n",
    "\n",
    "      return nll + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_grads(parameters, value=0.0):\n",
    "    \"\"\"Replace NaN gradients\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameters : Iterator[torch.Tensor]\n",
    "        Model parameters, usually you can get them by `model.parameters()`\n",
    "    value : float, optional\n",
    "        Value to replace NaNs with\n",
    "    \"\"\"\n",
    "    for p in parameters:\n",
    "        if p.grad is None:\n",
    "            continue\n",
    "        grads = p.grad.data\n",
    "        grads[torch.isnan(grads)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n",
      "  0%|          | 0/1 [47:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "Comenzo get_data\n",
      "Grid shape: (1, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([1, 5, 300])\n",
      "Shape Encoder: torch.Size([1, 64, 306])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x306 and 9792x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 12\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(results)\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[43], line 79\u001b[0m, in \u001b[0;36mModelV1.obtain_results\u001b[0;34m(self, light_curves)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaso el Get data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Encode the light_curves\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m encoding_mu, encoding_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#print(encoding_mu)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#print(encoding_logvar)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m time \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompare_data\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[43], line 49\u001b[0m, in \u001b[0;36mModelV1.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Flatten the output, keeping batch dimension\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#print('Shape after flattening:', x.shape)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_mean(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_logvar(x)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape mu:\u001b[39m\u001b[38;5;124m'\u001b[39m,mu\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x306 and 9792x64)"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    i = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Iteration over the batches\n",
    "    #for i, batch in enumerate(train_loader_synthetic):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        print(i)\n",
    "        results = model.obtain_results(batch)\n",
    "        loss = loss_function(results)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Puedes aÃ±adir un mensaje de final de epoch aquÃ­ si lo deseas\n",
    "    #if epoch % 10 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{num_epoch}], Loss: {train_loss / len(batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (32, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "Grid shape: (9, 2, 300)\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([9, 5, 300])\n",
      "Shape Encoder: torch.Size([9, 64, 306])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2754 and 9792x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 6\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(results)\n",
      "Cell \u001b[0;32mIn[43], line 79\u001b[0m, in \u001b[0;36mModelV1.obtain_results\u001b[0;34m(self, light_curves)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaso el Get data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Encode the light_curves\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m encoding_mu, encoding_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#print(encoding_mu)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#print(encoding_logvar)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m time \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompare_data\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[43], line 49\u001b[0m, in \u001b[0;36mModelV1.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Flatten the output, keeping batch dimension\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#print('Shape after flattening:', x.shape)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_mean(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_logvar(x)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape mu:\u001b[39m\u001b[38;5;124m'\u001b[39m,mu\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2754 and 9792x64)"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader:\n",
    "        results = model.obtain_results(batch)\n",
    "        predictions.append(results)\n",
    "        loss = loss_function(results)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f'Test Loss: {test_loss / len(batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([32, 5, 300])\n",
      "Shape Encoder: torch.Size([32, 64, 306])\n",
      "Shape mu: torch.Size([64, 20])\n",
      "Shape log_var: torch.Size([64, 20])\n",
      "Comenzo get_data\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5342/3808935312.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  nll = (0.5 * torch.tensor(results['obs_weight']) * torch.tensor(results['obs_flux'])**2)\n",
      "/tmp/ipykernel_5342/3808935312.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  kld = -0.5 * (1 + torch.tensor(results['encoding_logvar'], requires_grad=True)\n",
      "/tmp/ipykernel_5342/3808935312.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.tensor(results['encoding_mu'], requires_grad=True)**2\n",
      "/tmp/ipykernel_5342/3808935312.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  - torch.exp(torch.tensor(results['encoding_logvar'], requires_grad=True)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "fid:\n",
      " 0     1\n",
      "1     2\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "     ..\n",
      "95    2\n",
      "96    1\n",
      "97    2\n",
      "98    1\n",
      "99    2\n",
      "Name: fid, Length: 100, dtype: int64\n",
      "Creo el grid\n",
      "Paso el Get data\n",
      "Shape pre-encoder torch.Size([8, 5, 300])\n",
      "Shape Encoder: torch.Size([8, 64, 306])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x2448 and 9792x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_loader_synthetic:\n\u001b[0;32m----> 6\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobtain_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(results)\n",
      "Cell \u001b[0;32mIn[43], line 79\u001b[0m, in \u001b[0;36mModelV1.obtain_results\u001b[0;34m(self, light_curves)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaso el Get data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Encode the light_curves\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m encoding_mu, encoding_logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m#print(encoding_mu)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#print(encoding_logvar)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m time \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompare_data\u001b[39m\u001b[38;5;124m'\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[43], line 49\u001b[0m, in \u001b[0;36mModelV1.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Flatten the output, keeping batch dimension\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#print('Shape after flattening:', x.shape)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_mean(x), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_logvar(x)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape mu:\u001b[39m\u001b[38;5;124m'\u001b[39m,mu\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x2448 and 9792x64)"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_loss = 0.0\n",
    "    for batch in test_loader_synthetic:\n",
    "        results = model.obtain_results(batch)\n",
    "        predictions.append(results)\n",
    "        loss = loss_function(results)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    print(f'Test Loss: {test_loss / len(batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['redshift', 'time', 'obs_flux', 'obs_fluxerr', 'obs_weight', 'fid', 'encoding_mu', 'encoding_logvar'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0678e-25, 1.0480e-24, 6.9625e-25,  ..., 8.6663e-26, 3.7850e-26,\n",
      "         8.5787e-26],\n",
      "        [4.8742e-25, 7.2358e-25, 4.8016e-25,  ..., 8.6824e-26, 3.7878e-26,\n",
      "         8.5947e-26],\n",
      "        [5.2029e-25, 7.7220e-25, 5.1254e-25,  ..., 8.6796e-26, 3.7873e-26,\n",
      "         8.5919e-26],\n",
      "        ...,\n",
      "        [5.0331e-25, 7.4709e-25, 4.9581e-25,  ..., 8.6810e-26, 3.7875e-26,\n",
      "         8.5933e-26],\n",
      "        [7.0963e-25, 1.0522e-24, 6.9906e-25,  ..., 8.6661e-26, 3.7849e-26,\n",
      "         8.5786e-26],\n",
      "        [6.1455e-25, 9.1164e-25, 6.0539e-25,  ..., 8.6723e-26, 3.7860e-26,\n",
      "         8.5847e-26]])\n",
      "Predictions 0 shape obs_flux: torch.Size([32, 100])\n",
      "tensor([[ -4.1241,  -4.1241,  -2.0777,  ...,  94.1032,  96.1497,  96.1497],\n",
      "        [-29.1241, -29.1241, -27.0777,  ...,  69.1032,  71.1497,  71.1497],\n",
      "        [-29.1241, -29.1241, -27.0777,  ...,  69.1032,  71.1497,  71.1497],\n",
      "        ...,\n",
      "        [-29.1241, -29.1241, -27.0777,  ...,  69.1032,  71.1497,  71.1497],\n",
      "        [ -4.1241,  -4.1241,  -2.0777,  ...,  94.1032,  96.1497,  96.1497],\n",
      "        [-26.1241, -26.1241, -24.0777,  ...,  72.1032,  74.1497,  74.1497]])\n",
      "Predictions 0 shape obs_flux: torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0]['obs_flux'])\n",
    "print('Predictions 0 shape obs_flux:', predictions[0]['obs_flux'].shape)\n",
    "print(predictions[0]['time'])\n",
    "print('Predictions 0 shape obs_flux:', predictions[0]['time'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAACIuklEQVR4nO3dfXyN9f/A8dfZ/cY2jN0xMzeFCHMXJZTcRvd05yZSksQqIyHih5R0R7eoVPhSUWki9yRjFCYVM2Iztxtms51z/f44zmlnO2c75+zcn/ezxx6263zOdX2us5Pz9rl5v1WKoigIIYQQQngIH2d3QAghhBDCliS4EUIIIYRHkeBGCCGEEB5FghshhBBCeBQJboQQQgjhUSS4EUIIIYRHkeBGCCGEEB5FghshhBBCeBQJboQQQgjhUSS4EcJKKpXKrK9NmzZV+lr5+fm8+uqrZp/r2LFjBn3w9/cnIiKCtm3bMnbsWA4ePOiwvri6Ll26GLxWwcHBtGjRgnnz5qHRaOx+/U2bNpV5nwwZMoR69epZfK758+ezePHiMsd17wdjjwnhifyc3QEh3NWvv/5q8PNrr73Gxo0b2bBhg8Hxpk2bVvpa+fn5TJ06FdB+GJvrueee49FHH0Wj0XDx4kX27t3LwoULeffdd5k5cyYvvfSSw/riyurXr8+XX34JQE5ODh988AFjx44lKyuL2bNnO7w/kyZN4vnnn7f4efPnz6dmzZoMGTLE4HhMTAy//vorDRo0sFEPhXBtEtwIYaVbbrnF4OdatWrh4+NT5rgz1a1b16A/vXv3Jikpifvvv59x48bRrFkzevXq5cQeuobg4GCD16lXr140btyY9957j+nTp+Pv71/mOYqiUFBQQHBwsM37Y+sgJDAw0KXel0LYm0xLCWFH165dY/r06TRu3JjAwEBq1arFE088wZkzZwzabdiwgS5duhAREUFwcDB169blgQceID8/n2PHjlGrVi0Apk6dqp8+Kf2vc3MFBwfz6aef4u/vz5w5c/THz5w5w8iRI2natClVq1YlMjKSO+64g61bt+rbVNSXf/75hyeeeIJGjRoREhJC7dq16du3L/v376+wX61ataJTp05ljqvVamrXrs3999+vP7ZgwQJatGhB1apVCQ0NpXHjxrz88stWvR7G+Pv707p1a/Lz8/W/K5VKxahRo/jggw9o0qQJgYGBfPbZZwD8/fffPProo0RGRhIYGEiTJk14//33y5z3zz//pGfPnoSEhFCzZk1GjBjBpUuXyrQzNi2l0Wh49913admyJcHBwVSrVo1bbrmF1atXA1CvXj0OHjzI5s2b9b8X3TlMTUtt27aNO++8k9DQUEJCQujYsSM//vijQZvFixejUqnYuHEjzzzzDDVr1iQiIoL777+fU6dOGbQt730shCPJyI0QdqLRaLjnnnvYunUr48aNo2PHjmRmZjJlyhS6dOnC7t27CQ4O5tixY/Tp04dOnTqxcOFCqlWrxsmTJ0lJSeHatWvExMSQkpJCz549GTZsGE8++SSAPsiwRmxsLK1bt2bHjh0UFxfj5+fH+fPnAZgyZQrR0dFcvnyZb7/9li5duvDLL7/QpUuXCvty6tQpIiIimDVrFrVq1eL8+fN89tlntG/fnr1793LjjTea7NMTTzzB888/z99//02jRo30x3/++WdOnTrFE088AcDSpUsZOXIkzz33HG+88QY+Pj78888/pKenW/16GHPkyBH8/PyoXr26/th3333H1q1bmTx5MtHR0URGRpKenk7Hjh2pW7cub775JtHR0axdu5bRo0dz9uxZpkyZAsDp06fp3Lkz/v7+zJ8/n6ioKL788ktGjRplVn+GDBnCkiVLGDZsGNOmTSMgIIC0tDSOHTsGwLfffsuDDz5IeHg48+fPB7QjNqZs3ryZu+66i5tvvplPP/2UwMBA5s+fT9++ffn6668ZMGCAQfsnn3ySPn368NVXX3HixAleeuklHn/8cf00bEXv45CQELNfeyEqTRFC2MTgwYOVKlWq6H/++uuvFUBZuXKlQbvU1FQFUObPn68oiqKsWLFCAZR9+/aZPPeZM2cUQJkyZYpZfcnIyFAAZc6cOSbbDBgwQAGU06dPG328uLhYKSoqUu68807lvvvus6ovxcXFyrVr15RGjRopY8eOLbft2bNnlYCAAOXll182ON6/f38lKipKKSoqUhRFUUaNGqVUq1atwmubq3PnzspNN92kFBUVKUVFRcqpU6eU8ePHK4Dy0EMP6dsBSnh4uHL+/HmD5/fo0UOpU6eOkpuba3B81KhRSlBQkL59cnKyolKpyvye77rrLgVQNm7cqD82ePBgJT4+Xv/zli1bFECZOHFiufdy0003KZ07dy5zXPd+WLRokf7YLbfcokRGRiqXLl3SHysuLlaaNWum1KlTR9FoNIqiKMqiRYsUQBk5cqTBOV9//XUFULKyshRFMe99LISjePW01JYtW+jbty+xsbGoVCq+++47u15v5syZtG3bltDQUCIjI7n33ns5fPiwyfZPP/00KpWKefPm2bVfwj5++OEHqlWrRt++fSkuLtZ/tWzZkujoaP3umJYtWxIQEMBTTz3FZ599xtGjRx3SP0VRyhz74IMPSExMJCgoCD8/P/z9/fnll184dOiQWecsLi7m//7v/2jatCkBAQH4+fkREBDA33//XeE5IiIi6Nu3L5999pl+l9KFCxdYtWoVgwYNws9PO9Dcrl07Ll68yCOPPMKqVas4e/ashXde1sGDB/H398ff35/Y2FjefPNNHnvsMT7++GODdnfccYfBSE5BQQG//PIL9913HyEhIQa/5969e1NQUMDOnTsB2LhxIzfddBMtWrQwOOejjz5aYf9++uknAJ599tnK3ioAV65c4bfffuPBBx+katWq+uO+vr4MHDiQf//9t8zfTf369TP4+eabbwYgMzMTcN77WAhjvDq4uXLlCi1atOC9995zyPU2b97Ms88+y86dO1m3bh3FxcV0796dK1eulGn73Xff8dtvvxEbG+uQvgnbO336NBcvXiQgIED/wan7ys7O1n8oN2jQgPXr1xMZGcmzzz5LgwYNaNCgAW+//bZd+5eZmUlgYCA1atQAYO7cuTzzzDO0b9+elStXsnPnTlJTU+nZsydXr14165xJSUlMmjSJe++9l++//57ffvuN1NRUWrRoYdY5hg4dysmTJ1m3bh0AX3/9NYWFhQbriwYOHMjChQvJzMzkgQceIDIykvbt2+ufY40GDRqQmprK7t27OXDgABcvXmTJkiWEh4cbtIuJiTH4+dy5cxQXF/Puu++W+R337t0bQP97PnfuHNHR0WWubexYaWfOnMHX19estua4cOECiqKUuR9A/3fOuXPnDI5HREQY/Kyb8tL9Xp31PhbCGK9ec9OrV69yd4pcu3aNV155hS+//JKLFy/SrFkzZs+ebfX215SUFIOfFy1aRGRkJHv27OH222/XHz958iSjRo1i7dq19OnTx6prCefTLbws/XvXCQ0N1X/fqVMnOnXqhFqtZvfu3bz77ruMGTOGqKgoHn74YZv37eTJk+zZs4fOnTvrR0SWLFlCly5dWLBggUFbYwteTVmyZAmDBg3i//7v/wyOnz17lmrVqlX4/B49ehAbG8uiRYvo0aMHixYton379mW20z/xxBM88cQTXLlyhS1btjBlyhTuvvtu/vrrL+Lj483ur05QUBBt2rSpsJ1KpTL4uXr16vrRDlOjKgkJCYA2OMjOzi7zuLFjpdWqVQu1Wk12drbRgMRS1atXx8fHh6ysrDKP6RYJ16xZ0+LzOvp9LIQpXj1yU5EnnniC7du3s3TpUv744w8eeughevbsyd9//22T8+fm5gLo/+UM2kWoAwcO5KWXXuKmm26yyXWEc9x9992cO3cOtVpNmzZtynwZW1zr6+tL+/bt9Ttt0tLSgLL/Sq6Mq1ev8uSTT1JcXMy4ceP0x1UqVZkFqH/88UeZfD7l9cXYOX788UdOnjxpVt90gYJu4e7u3bsZOnSoyfZVqlShV69eTJw4kWvXrlUqOaE1QkJC6Nq1K3v37uXmm282+nvWjXh07dqVgwcP8vvvvxuc46uvvqrwOrp/hJUOPEsLDAw06z1SpUoV2rdvzzfffGPQXqPRsGTJEurUqcMNN9xQ4XlMMfU+FsJRvHrkpjxHjhzh66+/5t9//9UP07744oukpKSwaNGiMv8ytZSiKCQlJXHbbbfRrFkz/fHZs2fj5+fH6NGjK3V+4XwPP/wwX375Jb179+b555+nXbt2+Pv78++//7Jx40buuece7rvvPj744AM2bNhAnz59qFu3LgUFBSxcuBCAbt26AdpRnvj4eFatWsWdd95JjRo1qFmzZoVZbI8fP87OnTvRaDTk5ubqk/hlZmby5ptv0r17d33bu+++m9dee40pU6bQuXNnDh8+zLRp00hISKC4uFjfrry+3H333SxevJjGjRtz8803s2fPHubMmUOdOnXMft2GDh3K7NmzefTRRwkODi6za2f48OEEBwdz6623EhMTQ3Z2NjNnziQ8PJy2bdsC2im3Bg0aMHjwYD799FOzr22Nt99+m9tuu41OnTrxzDPPUK9ePS5dusQ///zD999/r99NNGbMGBYuXEifPn2YPn26frfUn3/+WeE1OnXqxMCBA5k+fTqnT5/m7rvvJjAwkL179xISEsJzzz0HQPPmzVm6dCnLli2jfv36BAUF0bx5c6PnnDlzJnfddRddu3blxRdfJCAggPnz53PgwAG+/vrrMqNUFTHnfSyEwzh5QbPLAJRvv/1W//Py5csVQKlSpYrBl5+fn9K/f39FUf7bgVDe17PPPmv0eiNHjlTi4+OVEydO6I/t3r1biYqKUk6ePKk/Fh8fr7z11lt2uWdhW6V3SymKohQVFSlvvPGG0qJFCyUoKEipWrWq0rhxY+Xpp59W/v77b0VRFOXXX39V7rvvPiU+Pl4JDAxUIiIilM6dOyurV682ONf69euVVq1aKYGBgQqgDB482GRfSr83fX19lerVqyutW7dWxowZoxw8eLDMcwoLC5UXX3xRqV27thIUFKQkJiYq3333XZmdO+X15cKFC8qwYcOUyMhIJSQkRLntttuUrVu3Kp07dza6i8eUjh07KoDy2GOPlXnss88+U7p27apERUUpAQEBSmxsrNK/f3/ljz/+KHP/5b1GOrrdUhUp7//njIwMZejQoUrt2rUVf39/pVatWkrHjh2V6dOnG7RLT09X7rrrLiUoKEipUaOGMmzYMGXVqlUV7pZSFEVRq9XKW2+9pTRr1kwJCAhQwsPDlQ4dOijff/+9vs2xY8eU7t27K6GhoQqgP4ex3VKKoihbt25V7rjjDqVKlSpKcHCwcssttxicT1H+2y2VmppqcHzjxo0G/Tb3fSyEI6gUxciWCS+kUqn49ttvuffeewFYtmwZjz32GAcPHsTX19egbdWqVYmOjqaoqIgjR46Ue97q1asTFRVlcOy5557ju+++Y8uWLfr5eIB58+aRlJSEj89/s4VqtRofHx/i4uL0+SyEEEIIYZpMS5nQqlUr1Go1OTk5RrOmgjaLaePGjc0+p6IoPPfcc3z77bds2rTJILAB7S6Q0sO3PXr0YODAgfoEZkIIIYQon1cHN5cvX+aff/7R/5yRkcG+ffuoUaMGN9xwA4899hiDBg3izTffpFWrVpw9e5YNGzbQvHlz/TZPSzz77LN89dVXrFq1itDQUP0uifDwcIKDg4mIiCiz3dLf35/o6OhyM7sKIYQQ4j9ePS21adMmunbtWub44MGDWbx4MUVFRUyfPp3PP/+ckydPEhERQYcOHZg6darJRXrlMbVAb9GiRSbrBNWrV48xY8YwZswYi68nhBBCeCOvDm6EEEII4Xkkz40QQgghPIoEN0IIIYTwKF63oFij0XDq1ClCQ0MtTlIlhBBCCOdQFIVLly4RGxtrkDLFGK8Lbk6dOkVcXJyzuyGEEEIIK5w4caLCrOdeF9zoihWeOHGCsLAwJ/dGCCGEEObIy8sjLi7OoOiwKV4X3OimosLCwiS4EUIIIdyMOUtKZEGxEEIIITyKBDdCCCGE8CgS3AghhBDCo3jdmhshhBCuT61WU1RU5OxuCAcLCAiocJu3OSS4EUII4TIURSE7O5uLFy86uyvCCXx8fEhISCAgIKBS55HgRgghhMvQBTaRkZGEhIRIslUvokuym5WVRd26dSv1u5fgRgghhEtQq9X6wCYiIsLZ3RFOUKtWLU6dOkVxcTH+/v5Wn0cWFAshhHAJujU2ISEhTu6JcBbddJRara7UeSS4EUII4VJkKsp72ep3L9NSNqLWqEnLSeNM/hlqhdQiMTIRXx9fZ3dLeDqNGjJ3wOXTUDUK4juCvO+EEF5OghsbWJ+5nlm7ZnE6/7T+WFRIFOPbjadbfDcn9kx4tPTVkJIMeaf+OxYWCz1nQ9N+zuuXEEI4mUxLVdL6zPUkbUoyCGwAcvJzSNqUxPrM9U7qmfBo6ath+SDDwAYgL0t7PH21c/olhItQaxR+PXKOVftO8uuRc6g1it2upVKpyv0aMmSI1eeuV68e8+bNM6ud7nrBwcHUq1eP/v37s2HDBouvOWTIEO69917LO1vC6dOn8ff3Z8mSJUYff/rpp7n55psrdY3yyMhNJag1ambtmoVC2f9pFBRUqJj12yyq+lflfMF5ma4StqFRa0dsjLzvtMdU8FMyBIXDlTMyXSW8TsqBLKZ+n05WboH+WEx4EFP6NqVnsxibXy8rK0v//bJly5g8eTKHDx/WHwsODrb5NY2ZNm0aw4cP59q1axw7dowlS5bQrVs3XnvtNSZOnOiQPuhERUXRp08fFi1axOOPP27w2NWrV1m6dCnTpk2z2/Vl5KYS0nLSyozYlKSgcPrqaYavG07y1mSGrh1Kj5U9ZDRHVE7mjrIjNgYUuHQKPu8HK4fBZ3fDvGYymiO8QsqBLJ5ZkmYQ2ABk5xbwzJI0Ug5kmXim9aKjo/Vf4eHhqFQqg2NbtmyhdevWBAUFUb9+faZOnUpxcbH++a+++ip169YlMDCQ2NhYRo8eDUCXLl3IzMxk7Nix+lGZ8oSGhhIdHU3dunW5/fbb+eijj5g0aZJBsKVWqxk2bBgJCQkEBwdz44038vbbbxv05bPPPmPVqlX6a27atAmA5ORkbrjhBkJCQqhfvz6TJk0qN4v0sGHD2LhxI8eOHTM4vmLFCgoKCsoEPbYkwU0lnMk/Y/FzZLrKPGqNmtTsVNYcXUNqdipqTeW2BXqUy6YDapNkuso8GjVkbIX9K7R/yvvO6RRFIf9asVlflwqKmLL6oMkxTYBXV6dzqaCownMpim2msdauXcvjjz/O6NGjSU9P58MPP2Tx4sXMmDED0H7Qv/XWW3z44Yf8/ffffPfddzRv3hyAb775hjp16jBt2jSysrIMRojM9fzzz6MoCqtWrQK0ifLq1KnD8uXLSU9PZ/Lkybz88sssX74cgBdffJH+/fvTs2dP/TU7duwIaIOnxYsXk56ezttvv83HH3/MW2+9ZfLavXv3Jjo6msWLFxscX7hwIffee69dcxnJtFQl1AqpZfFzZLqqYuUt0O4a11V2pVWNsuJJMl1VofIWaDfuI7vSnORqkZqmk9fa5FwKkJ1XQPNXf66wbfq0HoQEVP4jcsaMGYwfP57BgwcDUL9+fV577TXGjRvHlClTOH78ONHR0XTr1g1/f3/q1q1Lu3btAKhRowa+vr76ERlr1KhRg8jISP3oib+/P1OnTtU/npCQwI4dO1i+fDn9+/enatWqBAcHU1hYWOaar7zyiv77evXq8cILL7Bs2TLGjRtn9Nq+vr4MGjSIxYsXM2XKFFQqFRkZGWzevJmUlBSr7sdcEtxUQmJkIlEhUeTk5xhdd2NKyekqHW/dXVV6C/2Fggu8uPnFMq9nTn4OYzeNJTwwnNzCXP1xr3zd4jtqP3TzsjC+7saUEtNVOt66u6r0Fvr8c/C/IZR5PfOyYPlACK4BV8//d9xbXzdhsT179pCamqofqQHt1FBBQQH5+fk89NBDzJs3j/r169OzZ0969+5N37598fOz3cezoigGU1offPABn3zyCZmZmVy9epVr167RsmXLCs+zYsUK5s2bxz///MPly5cpLi4mLCys3OcMGzaM2bNns2HDBu68804WLlxInTp16NbNvn9nS3BTCb4+voxvN56kTUmoUFkU4JSmm66a22Wu13xQGxuh8VH5mFygDRgENuCdrxs+vtoP1uWDABWWBTil6Kar+n/uPR/UxkZoVD6YXqCNYWAD3vm6OUmwvy/p03qY1XZXxnmGLEqtsN3iJ9rSLqFGhde1BY1Gw9SpU7n//vvLPBYUFERcXByHDx9m3bp1rF+/npEjRzJnzhw2b95cqfIDOufOnePMmTMkJCQAsHz5csaOHcubb75Jhw4dCA0NZc6cOfz222/lnmfnzp08/PDDTJ06lR49ehAeHs7SpUt58803y31eo0aN6NSpE4sWLaJr16589tlnPPHEEzap/F0eCW4qqVt8N+Z2mVvmQ9pS3jZdpdtCXzqQ0Sgai86je91m75pN17iuHvlaGdW0n/aDtfSHtMW8bLpKt4W+dCBj4ftO/7qljNdOWXnia+UiVCqV2dNDnRrVIiY8iOzcAqOhqgqIDg+iU6Na+Po4JgtyYmIihw8fpmHDhibbBAcH069fP/r168ezzz5L48aN2b9/P4mJiQQEBFSqFMHbb7+Nj4+Pfmv31q1b6dixIyNHjtS3OXLkiMFzjF1z+/btxMfHG+y6yszMNKsPw4YN45lnnuGee+7h33//5YknnrDybswnwY0NdIvvZrAWJCI4gonbJsp0lQnlbaG3hoJCdn42aTlptI1ua5NzuoWm/QzXgoTUhFXPyHSVKeVuobeGAnknta9/QicbnVNUhq+Piil9m/LMkrQyY5q6UGZK36YOC2wAJk+ezN13301cXBwPPfQQPj4+/PHHH+zfv5/p06ezePFi1Go17du3JyQkhC+++ILg4GDi4+MB7dqWLVu28PDDDxMYGEjNmjVNXuvSpUtkZ2dTVFRERkYGS5Ys4ZNPPmHmzJn64Kphw4Z8/vnnrF27loSEBL744gtSU1P1Izu6a65du5bDhw8TERFBeHg4DRs25Pjx4yxdupS2bdvy448/8u2335r1Gjz00EOMHj2ap59+mjvvvJN69epZ/4KaSXZL2Yivjy9to9vSu35v2se0Z3y78QCoqNz/RJ6yu6rk7qev/vyqUqNcplize83t+fhqP1ibPwgNumgDEoBKvu88ZndVyd1Pv31QyVEuE6zZvSbspmezGBY8nkh0eJDB8ejwIBY8nmiXPDfl6dGjBz/88APr1q2jbdu23HLLLcydO1cfvFSrVo2PP/6YW2+9lZtvvplffvmF77//Xr+TaNq0aRw7dowGDRpQq1b5m1gmT55MTEwMDRs2ZODAgeTm5vLLL7+QnJysbzNixAjuv/9+BgwYQPv27Tl37pzBKA7A8OHDufHGG2nTpg21atVi+/bt3HPPPYwdO5ZRo0bRsmVLduzYwaRJk8x6DUJCQnj44Ye5cOECQ4cOteTls5pKsdV+NzeRl5dHeHg4ubm5FS6Eqixja0qsoUJFZHAk02+b7pbTVbZ6HSoyru04IoIi3O71sTlja0qsooLQGLjvA/ecrrLZ61CBHv+nfW3c7fVxQQUFBWRkZJCQkEBQUFDFTyiHWqOwK+M8OZcKiAwNol1CDYeO2AjrlPcesOTzW4IbOyu5G8ja6Spj3GW6ytTaGlvzUfkYrNdxl9fHbkruBrJ6usoId5muMrW2xtZUPobrddzl9XFRtgxuhHuyVXAj01J25s3TVZVZW+OjMnxrVguoBph+3UovRHaH18euvHm6qjJra0q97wjW7agx8bqVXojsDq+PEF5AFhQ7mKfvrio5UnWu4JzF96gLXubcPofqQdUNkvVtPLHR6NZxYzusvHYXlSmevruq5EjV5dNW3OP14OWBRVAlwjBZ358/Gt86bnSHleyiEsIVyLSUk3jidJUt1tZEh0ST3C7ZZP9LB0+vp75e4TkX9ljoXbuoyuOJ01W2WFsTVht6zjLd/9LB09qXKz7n4B9kF5WFZFpK2GpayqkjN1u2bGHOnDns2bOHrKwsvv322wrLrG/evJmkpCQOHjxIbGws48aNY8SIEY7psA3ppqt0bJ0M8I3Ob5QZ+bDl6IW5mYXNYclC4JKv25qja8w6v1fuojJFN12lY+tkgA8uLjvyYcvRC3MzC5vDkoXAJV+3/SvMO7/sohLCaZwa3Fy5coUWLVrwxBNP8MADD1TYPiMjg969ezN8+HCWLFnC9u3bGTlyJLVq1TLr+a7MltNVAC9tecnoAltb1GayJLNweVSoiAqJ4tHGj1oVeJlb28uaGmBew6bTVcDKJ4wvsLVFbSaLMguXR6XtV/sR1gVe5tb2sqoGmBDCFpwa3PTq1YtevXqZ3f6DDz6gbt26zJs3D4AmTZqwe/du3njjDbcPbsB2yQDB+ALb8mozmQp6zB2hsTSzsG5tTXK7ZKtHlCqq7aULnhIjE606v9ewWTJATCywLac2k6mgx9wRGoszC19fW9NzlvUjShXW9roePMV3tO78QohKc6sFxb/++ivdu3c3ONajRw8+/fRTioqKjNbhKCwspLCwUP9zXl6e3ftZGfaariqvNpOpoKd3Qm/WZKyp9AiNMVEhUeWurTFHebW9bBE8eRV7TVeVW5vJRNDT7EE4sMIGIzRGhMWWv7bGHObU9qpM8CSEqDS3Cm6ys7OJijIc6o2KiqK4uJizZ88SE1M28+TMmTMNyru7G1tNV5liKug5nX+aRQcXlWlv6QhNSfZIsmfq9bFF8OTVbDZdZYqpoOcU7HjHSHPr33d2SbJn6vXxr6JNeih5boRwKrcKbgCDsu2gLeVu7LjOhAkTSEpK0v+cl5dHXFyc/TpoB7acrnKGyq6tqUjp18cVtsR7BFtOVzlFJdfWVKTk63N0M2ydoz3eoKvtryWEsIhbJfGLjo4mOzvb4FhOTg5+fn76OhylBQYGEhYWZvDljuyVDNDeHDU9VPL1aRvdVgIbW7FXMkC7s8HaGnPoXp87JkJEIyi6An8st9/1hPlK1hXL2Kr92U5UKlW5X0OGDLH63PXq1dOvM62one56wcHB1KtXj/79+7NhwwaLrzlkyJAKdy6bq+TrULVqVVq0aMHixYttcu7yuFVw06FDB9atW2dw7Oeff6ZNmzZG19t4Mt10TGRIpMHx0pl9Ha309aNCopjbZa5MD3kK3XRMWKkpYCe/78pcPyxW209HTQ+pVNDmekHA3YvAu9KHuZ701TCvGXx2N6wcpv1zXjO7ZY7OysrSf82bN4+wsDCDY2+//bZdrlvatGnTyMrK4vDhw3z++edUq1aNbt26MWPGDIdc35RFixaRlZXF77//zoABA3jiiSdYu3atXa/p1L+RLl++zL59+9i3bx+g3eq9b98+jh8/DminlAYNGqRvP2LECDIzM0lKSuLQoUMsXLiQTz/9lBdffNEZ3Xe6bvHdWPvAWhb2WMjsTrNZ2GMhc26fg+r6f46ku+ac2+cY9CflgRQJbDxN034w5oA2Sd0Dn2r/fHAR2tESR4/oXL/mA4sM+zNmv+PXvbR4GPyC4PR++He3Y68t/qOrK1Z6rZgdS2NER0frv8LDw1GpVAbHtmzZQuvWrQkKCqJ+/fpMnTqV4uJi/fNfffVV6tatS2BgILGxsYwePRqALl26kJmZydixY/WjH+UJDQ0lOjqaunXrcvvtt/PRRx8xadIkJk+ezOHDhwFQq9UMGzaMhIQEgoODufHGGw2Cr1dffZXPPvuMVatW6a+5adMmAJKTk7nhhhsICQmhfv36TJo0iaKiogpfn2rVqhEdHU2DBg14+eWXqVGjBj///LOlL7NFnLrmZvfu3XTt+t/8tG5tzODBg1m8eDFZWVn6QAcgISGBNWvWMHbsWN5//31iY2N55513PGIbuLVK764CmKsqu8C2WkA1Ll67WOldVzrGClXKAl4vUnp3FYDKyAJb/W6oyu660l3DWKHKSu5+spWQGnDT/fD7V7B7IcRJVmybUBQoyjevrUYNP43D+HtNVxojGep3qXi60j9EOyJXSWvXruXxxx/nnXfeoVOnThw5coSnnnoKgClTprBixQreeustli5dyk033UR2dja///47AN988w0tWrTgqaeeYvjw4VZd//nnn+e1115j1apVjBs3Do1GQ506dVi+fDk1a9Zkx44dPPXUU8TExNC/f39efPFFDh06RF5eHosWaTeV1KihrbEWGhrK4sWLiY2NZf/+/QwfPpzQ0FDGjRtnVl/UajUrV67k/Pnzdp9tcWpw06VLF8qr/mBsXq5z586kpaXZsVfuz9QCW2O1mSwNesqr/eSK61xK5+lx1X56hNILkMurzWRx0FNO7SdX+n22HaYNbg6shCZ9tR/KrthPd1KUD/8Xa6OTKdr34SwzNpW8fAoCqlT6ijNmzGD8+PEMHjwYgPr16/Paa68xbtw4pkyZwvHjx4mOjqZbt274+/tTt25d2rVrB2iDCl9fX/2IjDVq1KhBZGQkx44dA8Df399gB3FCQgI7duxg+fLl9O/fn6pVqxIcHExhYWGZa77yyiv67+vVq8cLL7zAsmXLKgxuHnnkEXx9fSkoKECtVlOjRg2efPJJq+7HXG63W0qYx9iIjiVBT3RINL0SepXJc+NOIzTGMik7s/aWVzA2omNJ0BNWG5o9UDbPjSuN0JSndmuoVhcuHoelj/x33Jm1t4RT7dmzh9TUVIN1L2q1moKCAvLz83nooYeYN28e9evXp2fPnvTu3Zu+ffvi52e7j2dFUQymtD744AM++eQTMjMzuXr1KteuXaNly5YVnmfFihXMmzePf/75h8uXL1NcXGzWJp233nqLbt26ceLECZKSkhg7diwNGzaszC1VSIIbL2NJ0OPr48vzic+75cjH+sz1JG1KKjMapau9JYucHcySoMfHF7q9WvlyDc5w6HttYFOabr2HIxc5ewr/EO0oijkyd8CXD1bc7rEVFWeQ9g8x75oV0Gg0TJ06lfvvv7/MY0FBQcTFxXH48GHWrVvH+vXrGTlyJHPmzGHz5s02mbo5d+4cZ86cISEhAYDly5czduxY3nzzTTp06EBoaChz5szht99+K/c8O3fu5OGHH2bq1Kn06NGD8PBwli5dyptvvllhH6Kjo2nYsCENGzbkf//7H61ataJNmzY0bdq00vdnigQ3AjAe9JR33JWpNWpm7ZpldJpNQUGFitm7ZtM1rqtbBGoezVjQU95xV6ZRa0eijNKt9xivDejkfWc+lcr86aEGd5hXGqPBHQ77HSQmJnL48OFyRyqCg4Pp168f/fr149lnn6Vx48bs37+fxMREAgICUKut38b+9ttv4+Pjo9/avXXrVjp27MjIkSP1bY4cOWLwHGPX3L59O/Hx8UycOFF/LDMz0+L+NGzYkAceeIAJEyawatUqi59vLgluhMdJy0krN5uzgkJ2fjZpOWluF7gJF5a5o4JszgrkndS2c7fAzV2UWxrDQbmPSpk8eTJ33303cXFxPPTQQ/j4+PDHH3+wf/9+pk+fzuLFi1Gr1bRv356QkBC++OILgoODiY+PB7RrW7Zs2cLDDz9MYGAgNWvWNHmtS5cukZ2dTVFRERkZGSxZsoRPPvmEmTNn6oOrhg0b8vnnn7N27VoSEhL44osvSE1N1Y/s6K65du1aDh8+TEREBOHh4TRs2JDjx4+zdOlS2rZty48//si3335r1Wvywgsv0KJFC3bv3k2bNm2sOkdF3CrPjRDmOJN/xqbthDDLZTPLo5jbTljHVC4mR+c+uq5Hjx788MMPrFu3jrZt23LLLbcwd+5cffBSrVo1Pv74Y2699VZuvvlmfvnlF77//nt9Ytpp06Zx7NgxGjRoQK1atcq91uTJk4mJiaFhw4YMHDiQ3NxcfvnlF5KT/xtRHDFiBPfffz8DBgygffv2nDt3zmAUB2D48OHceOONtGnThlq1arF9+3buuecexo4dy6hRo2jZsiU7duxg0qRJVr0mzZs3p1u3bkyePNmq55tDpZS3XckD5eXlER4eTm5urttmKxblS81OZejaoRW2W9hjoYzcCNvJ2KpNFleRwT/IyI0JBQUFZGRkkJCQQFBQUOVOVrqyvLus2/Jy5b0HLPn8lmkp4XESIxOJCokyWXtLV+sqMTLRCb0THiu+o3nrPSpayCpswx3XbQmbkWkp4XF8fXxN1t5yVK0r4YV06z2AspmanbPeQwhvJcGN8Eimam9JrSthV6bWe4TGyDZwIRxIpqWExyovf48QdlMyf8+KoXAlB3rNgaZmrMcRQtiEBDfCo7ljnh7hAXTrPZr0hd2fwrEtEtwI4UAyLSWEEPbS4Hph4KObnNoNIbyNBDdCCGEv9W7TVjI/exhyTzq7N0J4DQluhBDCXoKrQ2wr7fcZm53bFyG8iAQ3QghhT/VlakoIR5PgRggh7Kl+F+2fRzeBdyWEF3bw6quv0rJlS/3PQ4YM0RfFtJYtzuFqJLgRQgh7imsH/iHaMgA5h5zdG6+h1qhJzU5lzdE1pGanotZYX1nbHEOGDEGlUqFSqfD396d+/fq8+OKLXLlyxa7Xffvtt1m8eLFZbY8dO4ZKpWLfvn1Wn8NdyFZwIYSwJ79AbcmFf9ZrR2+imjq7Rx5vfeZ6Zu2axen8/4qURoVEMb7deLsm8OzZsyeLFi2iqKiIrVu38uSTT3LlyhUWLFhg0K6oqAh/f3+bXDM8PNwlzuFqZORGCCHsTT81tdGp3fAG6zPXk7QpySCwAcjJzyFpUxLrM9fb7dqBgYFER0cTFxfHo48+ymOPPcZ3332nn0pauHAh9evXJzAwEEVRyM3N5amnniIyMpKwsDDuuOMOfv/9d4Nzzpo1i6ioKEJDQxk2bBgFBQUGj5eeUtJoNMyePZuGDRsSGBhI3bp1mTFjBgAJCQkAtGrVCpVKRZcuXYyeo7CwkNGjRxMZGUlQUBC33XYbqamp+sc3bdqESqXil19+oU2bNoSEhNCxY0cOHz6sb/P777/TtWtXQkNDCQsLo3Xr1uzevdsWL7NZJLgRQgh70wU3x7ZD8TWndsWTqTVqZu2aZbRgru7Y7F2z7T5FpRMcHExRUREA//zzD8uXL2flypX6aaE+ffqQnZ3NmjVr2LNnD4mJidx5552cP38egOXLlzNlyhRmzJjB7t27iYmJYf78+eVec8KECcyePZtJkyaRnp7OV199RVRUFAC7du0CYP369WRlZfHNN98YPce4ceNYuXIln332GWlpaTRs2JAePXro+6UzceJE3nzzTXbv3o2fnx9Dhw7VP/bYY49Rp04dUlNT2bNnD+PHj7fZaJU5ZFpKCCHsLfImqFILrpyBf1Oh3q3O7pFHSstJKzNiU5KCQnZ+Nmk5aXbPXL5r1y6++uor7rzzTgCuXbvGF198Qa1atQDYsGED+/fvJycnh8DAQADeeOMNvvvuO1asWMFTTz3FvHnzGDp0KE8++SQA06dPZ/369WVGb3QuXbrE22+/zXvvvcfgwYMBaNCgAbfddhuA/toRERFER0cbPYduGm3x4sX06tULgI8//ph169bx6aef8tJLL+nbzpgxg86dOwMwfvx4+vTpQ0FBAUFBQRw/fpyXXnqJxo0bA9CoUSMrX0nryMiN8EqOXmwovJyPDyRoPwRI+xz2r4CMrSDvO5s6k3/Gpu0s9cMPP1C1alWCgoLo0KEDt99+O++++y4A8fHx+uACYM+ePVy+fJmIiAiqVq2q/8rIyODIkSMAHDp0iA4dOhhco/TPJR06dIjCwkJ9QGWNI0eOUFRUxK23/heA+/v7065dOw4dMlwQf/PNN+u/j4nRFovNyckBICkpiSeffJJu3boxa9Ys/T05iozcCK/jrMWGwssFVdP++cdS7RdAWCz0nC3Vwm2kVkitihtZ0M5SXbt2ZcGCBfj7+xMbG2swDVOlShWDthqNhpiYGDZt2lTmPNWqVbPq+sHBwVY9ryTleroClUpV5njpYyXvT/eYRqMBtFvWH330UX788Ud++uknpkyZwtKlS7nvvvsq3UdzyMiN8CrOXGwovFj6am0BzdLysmD5IO3jotISIxOJColChcro4ypURIdEkxiZaJfrV6lShYYNGxIfH1/h+pLExESys7Px8/OjYcOGBl81a9YEoEmTJuzcudPgeaV/LqlRo0YEBwfzyy+/GH08ICAAALXa9Ihhw4YNCQgIYNu2bfpjRUVF7N69myZNmpR7T6XdcMMNjB07lp9//pn777+fRYsWWfT8ypDgRngNV1tsKLyERg0pyWDkfac/ljJepqhswNfHl/HtxgOUCXB0Pye3S8bXx9fhfSutW7dudOjQgXvvvZe1a9dy7NgxduzYwSuvvKLfVfT888+zcOFCFi5cyF9//cWUKVM4ePCgyXMGBQWRnJzMuHHj+Pzzzzly5Ag7d+7k00+1gXVkZCTBwcGkpKRw+vRpcnNzy5yjSpUqPPPMM7z00kukpKSQnp7O8OHDyc/PZ9iwYWbd29WrVxk1ahSbNm0iMzOT7du3k5qaanFwVBkS3AivYcliQyFsJnMH5J0qp4ECeSe17USldYvvxtwuc4kMiTQ4HhUSxdwuc11m6lmlUrFmzRpuv/12hg4dyg033MDDDz/MsWPH9LubBgwYwOTJk0lOTqZ169ZkZmbyzDPPlHveSZMm8cILLzB58mSaNGnCgAED9Otg/Pz8eOedd/jwww+JjY3lnnvuMXqOWbNm8cADDzBw4EASExP5559/WLt2LdWrVzfr3nx9fTl37hyDBg3ihhtuoH///vTq1YupU6da8ApVjkpRvCsfeF5eHuHh4eTm5hIWFubs7ggHWnN0DclbkytsN7vTbHrX7+2AHgmvsH8FrDTjX7wPfArNH7R/f1xYQUEBGRkZJCQkEBQUVKlzqTVq0nLSOJN/hlohtUiMTHSJERtRvvLeA5Z8fsuCYuE1nL3YUHipqlG2bSfM4uvja/ft3sJ1ybSU8BrOXmwovFR8R+2uKBPvO1BBWG1tOyGETUhwI7yGOy02FB7Ex1e73RsoG+Bc/7nnLG07IYRNSHAjvIq7LDYUHqZpP+j/OYTFGB4Pi9Uelzw3QtiUrLkRXqdbfDe6xnWVxYbCsZr2g8Z9tBmKfxgD/lVg9O/g57h6O+7Cy/a5iBJs9buX4EZ4JVlsKJzCxxdaDYSUCVB0Bc4fgcjGzu6Vy9AlvsvPz7dJtl3hfq5d0xaW9fWt3D82JbgRQghH8vWD2omQuV1bRFOCGz1fX1+qVaumz8sSEhJSJuW/8FwajYYzZ84QEhKCn1/lwhMJboQQwtHqtL0e3OyCxIHO7o1L0VWr1gU4wrv4+PhQt27dSge1EtwIIYSjxbXT/nki1bn9cEEqlYqYmBgiIyMpKipydneEgwUEBODjU/m9ThLcCCGEo9W5Htyc+RMKciEo3Ln9cUG+vr6VXnchvJdsBRdCCEerWguq1wMU+He3s3sjhMeR4EYIIZyhzvXdehLcCGFzEtwIIYQz6Kam/t3l3H4I4YEkuBFCCGeI043cpIJG49y+COFhJLgRQghniGoGfsHaBcXn/nZ2b4TwKBLcCCGEM/j6Q2wr7ff/ypZwIWxJghshhHAW3dTUCVl3I4QtSXAjhBDOol9ULCM3QtiSBDdCCOEsuu3gOYe0a2+EEDYhwY0QQjhLaBRUqwsocHKPs3sjhMeQ4EYIIZxJPzUlyfyEsBWpLSVECWqNmrScNM7kn6FWSC0SIxPx9ZH6NsKO4trBgRVwOAVq1IeqURDfEeR9J4TVJLgR4rr1meuZtWsWp/NP649FhUQxvt14usV3c2LPhEcruqr989QeWDlM+31YLPScDU37Oa9fQrgxmZYSAm1gk7QpySCwAcjJzyFpUxLrM9c7qWfCo6WvhvWvlj2elwXLB2kfF0JYTIIb4fXUGjWzds1CQSnzmO7Y7F2zUWvUju6a8GQaNaQkg5H3nf5YynhtOyGERSS4EV4vLSetzIhNSQoK2fnZpOWkObBXwuNl7oC8U+U0UCDvpLadEMIiEtwIr3cm/4xN2wlhlsumA2qr2gkh9CS4EV6vVkgtm7YTwixVo2zbTgih5/TgZv78+SQkJBAUFETr1q3ZunVrue2//PJLWrRoQUhICDExMTzxxBOcO3fOQb0VnigxMpGokChUqIw+rkJFdEg0iZGJDu6Z8GjxHbW7oky870AFYbW17YQQFnFqcLNs2TLGjBnDxIkT2bt3L506daJXr14cP37caPtt27YxaNAghg0bxsGDB/nf//5HamoqTz75pIN7LjyJr48v49uNBygT4Oh+Tm6XLPluhG35+Gq3ewNlA5zrP/ecJfluhLCCU4ObuXPnMmzYMJ588kmaNGnCvHnziIuLY8GCBUbb79y5k3r16jF69GgSEhK47bbbePrpp9m9WzJ7isrpFt+NuV3mEhkSaXA8KiSKuV3mSp4bYR9N+0H/zyEsxvB4WKz2uOS5EcIqTkvid+3aNfbs2cP48eMNjnfv3p0dO4zvDujYsSMTJ05kzZo19OrVi5ycHFasWEGfPn1MXqewsJDCwkL9z3l5eba5AeFxusV3o2tcV8lQLByraT9o3Af2fAY/jgX/KjD6d/Dzd3bPhHBbThu5OXv2LGq1mqgow8VyUVFRZGdnG31Ox44d+fLLLxkwYAABAQFER0dTrVo13n33XZPXmTlzJuHh4fqvuLg4m96H8Cy+Pr60jW5L7/q9aRvdVgIb4Rg+vpA4EPyCoegKXMhwdo+EcGtOX1CsUhnONSuKUuaYTnp6OqNHj2by5Mns2bOHlJQUMjIyGDFihMnzT5gwgdzcXP3XiRMnbNp/IYSwCV9/iG2l/f7fXc7tixBuzmnTUjVr1sTX17fMKE1OTk6Z0RydmTNncuutt/LSSy8BcPPNN1OlShU6derE9OnTiYmJKfOcwMBAAgMDbX8DQghha3Ft4fgOOPEbtHrc2b0Rwm05beQmICCA1q1bs27dOoPj69ato2NH41sf8/Pz8fEx7LKvr3baQFGMpTAXQgg3Uqed9s8Tqc7thxBuzqnTUklJSXzyyScsXLiQQ4cOMXbsWI4fP66fZpowYQKDBg3St+/bty/ffPMNCxYs4OjRo2zfvp3Ro0fTrl07YmNjnXUbQghhG3HXg5szf0JBrnP7IoQbc9q0FMCAAQM4d+4c06ZNIysri2bNmrFmzRri4+MByMrKMsh5M2TIEC5dusR7773HCy+8QLVq1bjjjjuYPXu2qUsIIYT7qBoJ1eLhYib8uxsa3unsHgnhllSKl83n5OXlER4eTm5uLmFhYc7ujhBCGFr5JOz/H3SZAF3GV9xeCC9hyee303dLCSGEKEG/7kZ2TAlhLQluhBDClcS11f75727QaJzbFyHclAQ3QgjhSqKaaZP5FebC2b+c3Rsh3JIEN0II4Up8/aH29Qr0ksxPCKtIcCOEEK6mzvWpKVl3I4RVJLgRQghXo8t3868k8xPCGhLcCCGEq6lTIpnf1YtO7YoQ7kiCGyGEcDVVa0H1etrvT+52aleEcEcS3AghhCuSOlNCWM2p5ReEcBdqjZq0nDTO5J+hVkgtEiMT8fXxdXa3hCeLawf7l8Pfa6FmI6gaBfEdQd53QlRIghshKrA+cz2zds3idP5p/bGokCjGtxtPt/huTuyZ8GhFV7V/ntoLK4dpvw+LhZ6zoWk/5/VLCDcg01JClGN95nqSNiUZBDYAOfk5JG1KYn3meif1THi09NWwbnLZ43lZsHyQ9nEhhEkS3AhhglqjZtauWSiUrS2rOzZ712zUGrWjuyY8mUYNKclg5H2nP5YyXttOCGGUBDdCmJCWk1ZmxKYkBYXs/GzSctIc2Cvh8TJ3QN6pchookHdS204IYZQEN0KYcCb/jE3bCWGWy6YDaqvaCeGFJLgRwoRaIbVs2k4Is1SNsm07IbyQBDdCmJAYmUhUSBQqVEYfV6EiOiSaxMhEB/dMeLT4jtpdUSbed6CCsNradkIIoyS4EcIEXx9fxrcbD1AmwNH9nNwuWfLdCNvy8dVu9wbKBjjXf+45S/LdCFEOCW6EKEe3+G7M7TKXyJBIg+NRIVHM7TJX8twI+2jaD/p/DmExhsfDYrXHJc+NEOVSKYpibL+hx8rLyyM8PJzc3FzCwsJsdl7JYOvZXPX3q9Yo7Mo4T86lAiJDg2iXUANfH1PTGcLtaNRwdBN8NQA0RfDMrxDV1Nm9EsIpLPn8lgzFNiAZbD2fr48vbaPbOrsbBlIOZDH1+3Sycgv0x2LCg5jStyk9m8WU80zhNnx8oeGd2vU1GZvh2DYJboQwg0xLVZJksBXOkHIgi2eWpBkENgDZuQU8sySNlANZTuqZsIuE27V/Zmx2bj+EcBMS3FSCZLAVzqDWKEz9Pr28/LVM/T4dtcarZpw9W/0u2j+PbZXMxEKYQaalKsHcDLZf/fkVEUERLrVWQ7ivXRnny4zYlKQAWbkFLN6eQc3QQFmL4wliWkJgGBTkQtbvUFvSDwhRHgluKsHczLSvp76u/17W4ojKyrlkOrAp6bUfD+m/l7U4bs7XD+rdBofXaKemJLgRolwyLVUJ1mSmlbU4orIiQ4Msfo6sxfEACZ21fx6VdTdCVERGbipBl8E2Jz/H6LobYxQUVKiY9dssqvpX5XzBeZmuEhZpl1CDmPAgsnMLzHzXaaeqVMCrqw8SGuTP2cuFMl3lbnSLio/vhOJC8At0bn+EcGGS56aSdLulALMDHGNkukpYQrdbCqjEu06mq9yKosAbN8CVHBjyo3aaSggvYsnnt0xLVZKpDLaWkukqYYmezWJY8Hgi0eGWT1GVJNNVbkSl+m/0RqamhCiXjNzYSMkMtucKzhksIjaXChVRIVGkPJAiU1TCLCUzFJ+9VGiwiNhcKiA6PIhtyXfIFJWrS/scVj8Hce1h2M/O7o0QDmXXDMWnT58mKirK6GN//PEHN998s6Wn9AglM9iqNWo+O/iZRWtxQLaOC8v5+qjo0CAC0AY6n2zLsGgtDsjWcbeiW1R8cg8UXoLAUOf2RwgXZfHITWRkJJ988gn9+hkWbnvjjTeYNGkSV69etWkHbc1eIzelyVoc4QyyFscLzLsZLmbCo/+DG7o7uzdCOIxd19wkJyczYMAARowYwdWrVzl58iR33HEHc+bMYdmyZVZ32tPIWhzvoNaoSc1OZc3RNaRmpzo9G7WsxfEC9a+P3uz7EvavgAzJWixEaVatufn99995/PHHKSgo4Pz589xyyy0sXLjQ5HSVK3HUyI1OybU4EcERTNw20eLpKhUqIoMjmX7bdNk6boIzqna7csHUkmtxalYJ5IX//c7pPMumq1RAVFggb/ZvKVvHTXBKVfaUCbBzvuGxsFjoORua9jP+HCE8gCWf31YFN5cuXWL48OGsXLkSgE8++YTBgwdb11sHc3RwU5pMV9leeUFG17iudgl6dL/H0r9DFdoPtrld5rrU70amq2yvvKrsdzWNtk/Qk74alg+i7G/x+rn7fy4BjvBYdg1utm/fzuOPP05ERARffPEF27dvJykpiZ49e/Lhhx9SvXr1SnXe3pwd3IDxD2NLueqHqKOVF2QoKIQHhpNbmKs/bougUK1R02NlD5O/P1fd9Wbsw9hSuo/nBY8nenWAowsWjYUYClAtxJ+L+UX64zYJCjVqmNcM8k6ZaKDSjuCM2Q8u9L4TwlbsGtwEBgYyduxYXnvtNfz9/QE4cuQIAwcO5Pjx4/z777/W99wBXCG4AdttHfe26Spj03yWBIm2CApTs1MZunZohe0W9lio30HnKmy1ddzbpquMTfNl55kfJNokKMzYCp/dXXG7wT9AQifrriGEC7PrVvCff/6Zzp07Gxxr0KAB27ZtY8aMGZaezmvZauv46aunGb5uuP6YJ09X2WLES1f+Yvau2XSN62pVIGhuwVRz2zmSrbaOZ+cV8tgnv+mPefJ0lS1GvHTlL6Z+n85dTaOtCwQvm/m+N7edEB7M4t1SpQMb/Yl8fJg0aVKlO+SNfH18Gd9uPPDfyIK1PHV3lW76qTKBjY4un1BaTppVzze3YKo1hVUdyddHxZS+TQEq+a7z3N1VuumnygQ2Orp8Qrsyzlt3gqpmbtgwt50QHszikZtp06aV+/jkyZOt7ow3020dt9XIhCcV5lRr1MzaNatSC7CNsXZkpaKCqbo1N4mRiZXtot3pto7bamTCkwpzqjUKU79Pt/G7DnIuWfk6x3fUrqnJy8L4svDra27iO1ame0J4BIvX3LRq1crg56KiIjIyMvDz86NBgwakpVn3r2FHcZU1N6bYYuu4Me42XWWLNUkVqcyaGFO73tx1obctto4b427TVbZYk1SRr4ffop8atJh+txQYBjiyW0p4PrtvBTd2wSFDhnDfffcxcODAyp7Orlw9uCnNVlvH3elD1xZra8pjq91MxvoZHRJNcrtkl3+NK2KrrePutLvKFmtrymOzGl7pqyEl2XDXVEhNuPstCWyER3N4cANw4MAB7r77bo4dO2aL09mNuwU3YLsPe3fYXWVqa7elqgVU4+K1i/ot4Tq2DvKckTzQUWz1Ye8Ou6tMbe22lG4LuG5LeGkf2CrI06ghcwdseR0ytkCrx+Ge9yt/XiFcmFOCm23bttG3b18uXLhgi9PZjTsGN+Ad01UV5Y8xxVTQtvHERpMjK/ZK7udpvGG6Sq1RuG32BouDOFNB27r0bKNBYdVAPza80JkjZ67YLrnf0c3weT8Irg4v/g2+/tafSwgXZ9fg5p133jH4WVEUsrKy+OKLL7j99tv5+uuvLe+xA7lrcFOaraer3uj8BtWDqjv8w76ya2sqGokxNrJiLOhxpSDPldl6uur9R1tRvUqgY8sXUPm1NRVNt5U8f42QAKb/mM7h05cJ8vehoEijb1fpIE+jhjcbw5UceGwFNLrLuvMI4QbsGtwkJCQY/Ozj40OtWrW44447mDBhAqGhoZb32IE8JbgB265N8VH5oFH++0vXER/2tui/pWtc3K1sgiuy5doUHxVoSvwqHDGiY4v+W9rPDzcfYeZPf5Y5bpM1ST++CKkfQ4tH4b4F1p1DCDfglGkpd+FJwQ3Yb7rK1iM6pUdQLhRc4MXNL1rVz3FtxxERFGFxf9y1bIIrstd0la1HdEoXtrxw5RrPfmXd2ppJfZpQMzTQ4v5UNO1V6YXGmTtgUS8IDIeX/ga/QMvPIYQbsGuGYuFaSmY6BhjfbjxJm5LKLKS1lO65L215yeiIjiVrVoyN0PiofCzuny74eLTxo1YFH2k5aeWOEpVM7udqZRNcTclMxwCv9mvKM0vSTC6kNZfuuaO+3mt0RMeSgpTGRmh8VJb3Txd8DLk1wargY1fG+XJHiUom97Nqi3jcLRAaC5dOwT+/QOPelp9DCA9jVnBz//33m33Cb775xurOiMqzVTJAnZKBDWgzII/dNNZkQcrSQY+pEZrS562IbiQpuV2y1aMq7lw2wdXZKhmgjqZUBJKdW8CIJWkmC1KWDnpMjdCUPm9FdKHMlL5NrV4LZG7SPquT+/n4wE33ws75cPAbCW6EwMzgJjw83N79EDbULb6bQZBhy+kq3fNLBjZgOuixZoTGmKiQqErnj/GUsgmuqmezGIMgw5bTVbrnlwxswHTQY80IjTHRNlgDFBkaZNN2Rt10vza4OfwTFF0F/2DrzyWEB5A1N17CVrurHMnatTWm6NbcVFQ2wRZrbjw5/40lbLW7ypGsXVtjim7NjakCpTZJ7qcoMO9myD0OXSZARENtjan4juCF7zvhmeyyoHjDhg3cfvvt+Pm59zIdbw1uwPTaF0uniOzNngt7HVE2wdjr7M1bzU2tfbF0isjebJZB2AhTQZ5NMzh//QgcXmN4LCwWes6WzMXCI9gluPH19SUrK4vIyEgAbrnlFlauXEnt2rUr32MH8ubgBkzvWgLXGNFxxJZse5ZNkK3mxpnatQSuMaLjiDIRxoK8GiH+/N/9zSt/zfTVsNxY6RupOSU8h12CGx8fH7Kzs/XBTWhoKL///jv169evfI8dyNuDG2OcOaJT+jqOqs1kj2kj2WpuGWeO6Dgjvw78F+Qt2PQPW/4+ywOJtXmzf8vKnVSjhnnNDGtNGbheLXzMfpmiEm5NtoILi5RegOyIER3dSMac2+c4JTNy6S30tiBbzS1TegGyI0Z0dCM07z3inMzIui30KhVs+fss6w/lUKTW4O/rY/1JM3eUE9gAKJB3UtsuoZP11xHCjZgd3KhUKlQqlcmfhXsz9mE/V1V2S7mpgpQVMZYB2ROqZ5ckW80tVzpfDsACn7JbyisqSGlK6REaW+x+soW29WpQs2oAZy9f49cj57j9hkrs0LtsZsoHc9sJ4QHMDm4UReHOO+/ULyjOz8+nb9++BAQEGLRLS0uzqAPz589nzpw5ZGVlcdNNNzFv3jw6dTL9r4vCwkKmTZvGkiVLyM7Opk6dOkycOJGhQ4dadF1RMWMjOqZqM1VUhdtZIzSOJFvNbcPYiI6pgpSmgh5nj9BUxNdHxV1No/l613F+OpBdueCmapRt2wnhAcwObqZMmWLw8z333FPpiy9btowxY8Ywf/58br31Vj788EN69epFeno6devWNfqc/v37c/r0aT799FMaNmxITk4OxcXFle6LMM7YiI4lQY8njtCYkhiZSFRIVIVbzRMjE53QO/dibETHkqDHVUZoytO7uTa4+flgNtPvbWZ90BXfUbumJi8L4+Na19fcxHesTHeFcCtOzXPTvn17EhMTWbDgv2JvTZo04d5772XmzJll2qekpPDwww9z9OhRatSoYdU1ZUGxfXl7fhdHbDUXZZXejeUqIzTlKVJraDN9PblXi/h6+C3WlV7QSV8Nywdd/6H0X+kq2S0lPIIln9+VWMVWOdeuXWPPnj10797d4Hj37t3ZsWOH0eesXr2aNm3a8Prrr1O7dm1uuOEGXnzxRa5evWryOoWFheTl5Rl8CfvRjfT0rt+bttFtvSqwgf/KX0SGRBocjwqJksDGjnQjPfe0rE2HBhEuH9gA+Pv6cFdT7VRRyoGsyp2saT9tABNWeqRKBfd/LIGN8DpO2y119uxZ1Go1UVGG88BRUVFkZ2cbfc7Ro0fZtm0bQUFBfPvtt5w9e5aRI0dy/vx5Fi5caPQ5M2fOZOrUqTbvvxCmmJq287ZAT1SsV7NoVuz5l5SD2UzpexM+lQnKmvaDxn20u6IuZcHPr2gXERdctFl/hXAXTt8KXnrHlaIoJndhaTQaVCoVX375pb7e1dy5c3nwwQd5//33CQ4uW09lwoQJJCUl6X/Oy8sjLi7OhncgPImtptXssdVceJ7bGtWkaqAfp/MK+WJnJtVC/Cs3rebj+99274JcWPMi/Po+tBkqOW6EV3FacFOzZk18fX3LjNLk5OSUGc3RiYmJoXbt2gaFPJs0aYKiKPz77780atSozHMCAwMJDAy0beeFR5KyCcLRAv18aRITSuqxC0xZfVB/3CZJBVs+ChtnwIUM+PNHmZoSXsVpa24CAgJo3bo169atMzi+bt06OnY0vqr/1ltv5dSpU1y+fFl/7K+//sLHx4c6derYtb/Cs+kWApdOwpeTn0PSpiTWZ663yXXUGjWp2amsObqG1OxU1Bq1Tc4r3FPKgSxSj10oczw7t4BnlqRVbi1OQBVo+6T2++3vQMZW2L9C+6e874SHM2u31DvvvGP2CUePHm1222XLljFw4EA++OADOnTowEcffcTHH3/MwYMHiY+PZ8KECZw8eZLPP/8cgMuXL9OkSRNuueUWpk6dytmzZ3nyySfp3LkzH3/8sVnXlN1SojRHlU2QkSFRkq5aeMkt7CXZpJDnpdPwVlPQlEqXIQU1hRuyefmFt956y+DnM2fOkJ+fT7Vq1QC4ePEiISEhREZGWhTcDBgwgHPnzjFt2jSysrJo1qwZa9asIT4+HoCsrCyOHz+ub1+1alXWrVvHc889R5s2bYiIiKB///5Mnz7d7GsKUZojyiaYKqipGxmSnVTeZ1fGeZOBDWg3dGflFrAr47z128RP/FY2sAFtTpzlg2SLuPBYZgU3GRkZ+u+/+uor5s+fz6effsqNN94IwOHDhxk+fDhPP/20xR0YOXIkI0eONPrY4sWLyxxr3LhxmaksISrD3mUT1Bo1s3bNMprYT0FBhYrZu2bTNa6r7KjyIjmXTAc21rQrQ6OGlGQTDyqAClLGa3dYyftOeBiL19xMmjSJd999Vx/YANx444289dZbvPLKKzbtnBCOYO+yCZaMDAnvERkaZNN2ZVhSUFMID2NxcJOVlUVRUVGZ42q1mtOnpTCbcD+6sgkqjK9rUKEiOiTa6rIJUlBTGNMuoQYx4UEm3nXaNTcx4dpt4VaRgprCi1kc3Nx5550MHz6c3bt3o1uLvHv3bp5++mm6dZM1A8L9+Pr4Mr7deIAyAY7u5+R2yVZPGUlBTWGMr4+KKX2bApQJcHQ/T+nb1PrFxFJQU3gxi4ObhQsXUrt2bdq1a0dQUBCBgYG0b9+emJgYPvnkE3v0UQi7s2fZBHuPDAn31bNZDAseTyQ63HDqKTo8iAWPJ1Yuz42uoGZ5Y0NhtaWgpvBIVhfO/Ouvv/jzzz9RFIUmTZpwww032LpvdiFbwUV57FX4UwpqivKoNQopB7J49qu9qIC0yXdRPSSg8ieWgprCgzikcGa9evW48cYb6dOnj9sENkJUxF6FP6WgpiiPr4+KPjfHUrdGCAqw78RF25zYZEFNoP0ICWyEx7K4/EJ+fj7PPfccn332GaAdwalfvz6jR48mNjaW8ePH27yTQngCKagpKtI+oQbHz+ezK+M8XW+MrPgJ5ihZUPPyaTi6EfYu0ZZk6PYq+Fu5G0sIF2bxyM2ECRP4/fff2bRpE0FB//1P0a1bN5YtW2bTzgnhaUyNDElZBgHod0b9dvScbU+sK6jZ/EHoNQdCYyH3OPz2gZRlEB7J4pGb7777jmXLlnHLLbcYVO9u2rQpR44csWnnhPAGUpZB6LRP0GYi/uPfXK5eUxMcYIdRvYAQuGMirHoW1r+KwVocKcsgPITFIzdnzpwhMrLscOmVK1cMgh0hRMUcVbBTuIe4GsHEhAdRrFFIO162oKbNBFS9/k2pRca6sgzpq+13bSEcwOLgpm3btvz444/6n3UBzccff0yHDh1s1zMhPFxFZRkAZu+aLVNUXkSlUv03NZVx3j4X0ahh7QQTD15/L6aMlykq4dYsnpaaOXMmPXv2JD09neLiYt5++20OHjzIr7/+yubNm+3RRyE8kiMKdgr30z4hglX7TrErw8brbnQsKcuQ0Mk+fRDCziweuenYsSPbt28nPz+fBg0a8PPPPxMVFcWvv/5K69at7dFHITySlGUQxuhGbvYev0hhsR1GT6Qsg/ACFo/cADRv3ly/FVwIYR0pyyCMaVCrCjWrBnD28jX++DeXtvWsrC1lipRlEF7A4pGbrl278umnn5Kbm2uP/gjhNaQsgzDGYN2NrbeEg5RlEF7B4uCmefPmvPLKK0RHR/PAAw/w3Xffce3aNXv0TQiPZu+CncJ9tatnx0XFPr7a7d6AyQCn5yxtOyHclMXBzTvvvMPJkydZtWoVoaGhDB48mOjoaJ566ilZUCyEhaQsgzCmfX1tvps9mRcoVmtsf4HyyjI0f0jy3Ai3Z3XhTJ2CggK+//57ZsyYwf79+1GrXXv7oBTOFK7IVMFOexXyFK5No1Fo9do6cq8W8d2zt9IyrpqdLqT+ryzD6XTY9iYEhMKo3XDub+3xqlHaKSp53wkns+Tz26oFxTrZ2dksXbqUJUuW8Mcff9C2rWxXFcIaurIMJUnmYu/l46Oibb0arD90ml0Z5+wX3OjKMgDcpIGjG+DUXni3FRTl/9dOMhcLN2PxtFReXh6LFi3irrvuIi4ujgULFtC3b1/++usvfvvtN3v0UQinc3TtJ8lcLNpfX1Scsj+bVftO8uuRc6g1lRpoL5+PD9zYR/t9ycAGJHOxcDsWj9xERUVRvXp1+vfvz//93//JaI3weI4eQakoc7EKFbN3zaZrXFeZovJg6usrBtJOXCRt6T4AYsKDmNK3KT2bGVkrU1kaNexZaOJBBVBpMxc37iNTVMLlWTRyoygKb7/9Nv/88w/z5s2TwEZ4PGeMoFiSuVh4ppQDWcz+6c8yx7NzC3hmSRopB7Jsf1FLMhcL4eIsDm5GjRrFyZMn7dUfIVyGs2o/SeZi76bWKEz9Pt3Iu+6/MpdTv0+3/RSVZC4WHsSi4MbHx4dGjRpx7pydap4I4UKcNYIimYu9266M82TlFph8XAGycgvYZescOJK5WHgQixcUv/7667z00kscOHDAHv0RwmU4awRFMhd7t5xLpgMba9qZTTIXCw9icXDz+OOPs2vXLlq0aEFwcDA1atQw+BLCUzhrBEUyF3u3yNAgm7Yzm2QuFh7E4t1S8+bNs0M3hHA9uhGUnPwco+tuVKiIComyywiKLnOxsV1aye2SJc+NB2uXUIOY8CCycwuMrrtRAdHhQfr6Uzaly1yckmy4uNjHHx78VPLcCLdR6QzF7kYyFAtL6HZLAQYBjm4Exd4lEiRDsXdKOZDFM0u0a7lK/gWtG09Z8HiifbaD6+gyF587og10igvg4a+028CFcBJLPr8tnpYCOHLkCK+88gqPPPIIOTk5AKSkpHDw4EFrTieEy3J27Sdd5uLe9XvTNrqtBDZeomezGBY8nkh0uOHUU3R4kP0DG/gvc3GbIdDhWe2xTTPBu/4tLNyYxSM3mzdvplevXtx6661s2bKFQ4cOUb9+fV5//XV27drFihUr7NVXm5CRG2ENVxtBcbX+CPtQaxS2/3OGoYt3U6xRWDvmdm6MDnVsJ/LPw7yb4doleOgLCKkuNaeEU9i1ttT48eOZPn06SUlJhIb+9z9Z165defvtty3vrRBuwFjtJ2eRmlPew9dHxe03RNKmXnV2Hj3P7szzjg9uQmpA+6dh6xuwcihoiv57TGpOCRdl8bTU/v37ue+++8ocr1WrluS/EcLOpOaUd2qfEAHAzqM2zm1jrogG2j9LBjYgNaeEy7I4uKlWrRpZWWVTf+/du5fatWvbpFNCiLKclTFZON8t9bXBzW9Hz+HwPSAaNWx4zcSD1/uSMl7bTggXYXFw8+ijj5KcnEx2djYqlQqNRsP27dt58cUXGTRokD36KIRAak55s1Z1qxHg60POpUKOncuv+Am2JDWnhBuyOLiZMWMGdevWpXbt2ly+fJmmTZty++2307FjR1555RV79FEIgdSc8mZB/r60jKsGaEdvHEpqTgk3ZHFw4+/vz5dffsnff//N8uXLWbJkCX/++SdffPEFvr6yal4Ie5GaU96tfX1t0r6djg5upOaUcENW5bkBqF+/Pg8++CAPPPAAV65c4cKFC7bslxCiFKk55d30624yzjt23Y3UnBJuyOLgZsyYMXz66acAqNVqOnfuTGJiInFxcWzatMnW/RNCXCc1p7xbYt3q+PuqyMot4MT5q467cLk1p67/LDWnhIuxOLhZsWIFLVq0AOD777/n6NGj/Pnnn4wZM4aJEyfavINCiP84O2OycJ7gAF9urlMNcMLUlK7mVFipzMiBVbXHJc+NcDEWJ/E7e/Ys0dHRAKxZs4b+/ftzww03MGzYMN555x2bd1AIYahbfDe6xnWVDMVe6Jb6NdiTeYGdGefo3zbOsRdv2k9bWypzBxz+EXYuAJUfNLrLsf0QwgwWj9xERUWRnp6OWq0mJSWFbt20/1LMz8+XBcVCOIjUnPJOumR+vzkrmZ+u5tRd0yG8LhRcgP3/c05fhCiHxcHNE088Qf/+/WnWrBkqlYq77tJG7b/99huNGze2eQeFEEJotY6vjq+PipMXr3LivIPz3ZTk6wfthmu/3/mBFNQULsfi4ObVV1/lk08+4amnnmL79u0EBgYC4Ovry/jx423eQSGEEFpVAv1oXjsc0O6acqrEgeBfBXIOQsYW5/ZFiFIsXnMD8OCDD5Y5Nnjw4Ep3Rgh342rVuV2tP8L2bqkfwb4TF/n+95P4+6qIDA2iXUINfH1MbdW2k+Dq0PIRSP3k+vobH6kWLlyGVcHNL7/8wltvvcWhQ4dQqVQ0btyYMWPG6NffCOENXK06t6v1R9iH7/Xx9s1/nWXzX2cBiAkPYkrfpvRsFlPOM+2g/QhtcPPXT9ovHakWLpzM4mmp9957j549exIaGsrzzz/P6NGjCQsLo3fv3rz33nv26KMQLsfVqnO7Wn+EfaQcyGL+xiNljmfnFvDMkjRSDpQtamxXOYeMH5dq4cLJVIqFqS5r167NhAkTGDVqlMHx999/nxkzZnDqVHkF1pwvLy+P8PBwcnNzCQsLc3Z3hBtSa9T0WNnDZBFLFSqiQqJIeSDFIVNCrtYfYR9qjcJtszeQlVtg9HEVEB0exLbkOxwzRaVRw7xm5RTVVGlHcMbslykqYROWfH5bPHKTl5dHz549yxzv3r07eXl5lp5OCLfjatW5Xa0/wj52ZZw3GdgAKEBWbgG7HLXQWKqFCxdmcXDTr18/vv322zLHV61aRd++fW3SKSFcmatV53a1/gj7yLlkOrCxpl2lSbVw4cLMWlBcMvNwkyZNmDFjBps2baJDhw4A7Ny5k+3bt/PCCy/Yp5dCuBBXq87tav0R9hEZGmTTdpUm1cKFCzNrzU1CQoJ5J1OpOHr0aKU7ZU+y5kZUlm6NS05+Dgpl//dx1pobV+mPsA/dmpvs3AIjv2VnrrnJAlM9kjU3woZsvuYmIyPDrC9XD2yEsAVXq87tav0R9uHro2JK36aAydrcTOnb1HH5bqRauHBhFq+50Tl79iznzjm4Mq0QLsLVqnO7Wn+EffRsFsOCxxOJDjeceqpZNZAFjyc6Ps+NqWrhQeFSLVw4lUVbwS9evMjEiRNZtmwZFy5cAKB69eo8/PDDTJ8+nWrVqtmrnzYj01LCllwtI7Cr9UfYh1qjsCvjPK/9mE76qTzGdGvEmG43OK9DGrV2V9TeL+CPZRDVHJ7Z5rz+CI9kyee32cHN+fPn6dChAydPnuSxxx6jSZMmKIrCoUOH+Oqrr4iLi2PHjh1Ur17dJjdhLxLcCCE8xbLU4ySv3M9NsWH8OLqTs7sDV87B3MagvgZPbYLYVs7ukfAgdslzM23aNAICAjhy5AgffvghY8aMYezYsXz00Uf8888/+Pv7M23aNIs7O3/+fBISEggKCqJ169Zs3brVrOdt374dPz8/WrZsafE1hRDCE3RrEoWPCg6eynNulXCdKhHQ5HpKkD2fObcvwquZHdx89913vPHGG0RFld3WFx0dzeuvv240/015li1bxpgxY5g4cSJ79+6lU6dO9OrVi+PHj5f7vNzcXAYNGsSdd95p0fWEEMKTRFQNpG29GgD8nO4i+WQSrxdR3r8CCi87ty/Ca5kd3GRlZXHTTTeZfLxZs2ZkZ2dbdPG5c+cybNgwnnzySZo0acK8efOIi4tjwYIF5T7v6aef5tFHH9Xn2RFCCG/V46ZoANYetOzvX7up1wmqJ8C1S3DQsn/wCmErZgc3NWvW5NixYyYfz8jIICIiwuwLX7t2jT179tC9e3eD4927d2fHDtPpuhctWsSRI0eYMmWKWdcpLCwkLy/P4EsIb6PWqEnNTmXN0TWkZqei1qid3SVhI91v0o6mpx47z9nLhU7uDeDjA4mDtN/veE87gpOxVbvoWAgHMStDMUDPnj2ZOHEi69atIyAgwOCxwsJCJk2aZLTmlClnz55FrVaXmeaKiooyOQL0999/M378eLZu3Yqfn3ldnzlzJlOnTjW7X0J4mvWZ65m1a5ZB/amokCjGtxsvW8Q9QJ3qITSrHcaBk3msTz/Nw+3qOrtLUKWm9s+zf8LKYdrvw2K1eXFke7hwALNHbqZOncrhw4dp1KgRr7/+OqtXr2b16tXMmjWLRo0acejQIV599VWLO6BSGSZ/UhSlzDEAtVrNo48+ytSpU7nhBvO3PE6YMIHc3Fz914kTJyzuoxDuan3mepI2JZUprJmTn0PSpiTWZ653Us+ELfVo6kJTU+mrYfXossfzsmD5IO3jQtiZ2SM3derU4ddff2XkyJFMmDAB3Q5ylUrFXXfdxXvvvUdcXJzZF65Zsya+vr5lRmlycnKMLlq+dOkSu3fvZu/evYwaNQoAjUaDoij4+fnx888/c8cdd5R5XmBgIIGBgWb3SwhPodaombVrltGSDAoKKlTM3jWbrnFdJReOm+vRLJo31/3F9n/OcamgiNAgf+d0RKOGlGSMl2NQABWkjIfGfSRzsbArs4Mb0NaY+umnn7hw4QJ///03AA0bNqRGjRoWXzggIIDWrVuzbt067rvvPv3xdevWcc8995RpHxYWxv79+w2OzZ8/nw0bNrBixQqz618J4QiukEwvLSetzIhNSQoK2fnZpOWk0Ta6rQN7JmytUWRV6teswtGzV/h4y1EaRFYlMjSIdgk1HFeOAbSJ/PJOldNAgbyT2nYJLpCXR3gsi4IbnerVq9OuXbtKXzwpKYmBAwfSpk0bOnTowEcffcTx48cZMWIEoJ1SOnnyJJ9//jk+Pj40a9bM4PmRkZEEBQWVOS6EM7nKGpcz+Wds2k64LpVKRcPIqhw9e4V3NvyjPx4THsSUvk0dV5bhspnb0c1tJ4SVrK4tZQsDBgxg3rx5TJs2jZYtW7JlyxbWrFlDfHw8oN1+XlHOGyFciSutcakVUsum7YTrSjmQZTTPTXZuAc8sSSPlQJZjOlK17JKCSrUTwkoW1ZbyBFJ+QdiLWqOmx8oeJqeCVKiICoki5YEUh0xR6fqTk59jdN2No/sj7EOtUbht9gaycguMPq4CosOD2JZ8h/2nqDRqmNdMu3jY6LoblXbX1Jj9suZGWMwu5ReEEOWzZI2LI/j6+DK+3XhAG8iUpPs5uV2yBDZublfGeZOBDWhDjKzcAnZlnLd/Z3x8tdu9ATARSPWcJYGNsDsJboSwEVdc49Itvhtzu8wlMiTS4HhUSBRzu8yVPDceIOeS6cDGmnaV1rQf9P8cwoys8+mcLHluhENYtaBYCFGWq65x6Rbfja5xXZ2+e0vYR2RokE3b2UTTftrt3pk7tIuH96+Ev9bA+SOO64PwahLcCGEjiZGJRIVEVbjGJTEy0eF98/Xxle3eHqpdQg1iwoPIzi0wtcqF6HDttnCH8vH9b7t3jQRtcHPoe7h6EYKrObYvwuvItJQQNiJrXIQz+PqomNK3KWBylQtT+jZ1bL6b0mITIbIpFBfAgZXO64fwGhLcCGFDssZFOEPPZjEseDyR6HDDqScVMHdAS8fluTFFpYJWj2u/37vEuX0RXkGmpYSwMVnjIpyhZ7MY7moaza6M82TnFfD6T3+SlVfAGUctJK7IzQNg3WQ4lQan0yGqqbN7JDyYjNwIYQe6NS696/embXRbCWyEQ/j6qOjQIIL7WtVm7F3aAsOfbM2goEjt5J6hrRR+Q0/t9/u+dG5fhMeTkRshHMgVak65cn+E7dzbqjZvrf+LrNwC/rfnBA1rhZJzqcA5Nad0Wg2EP3+AtM8hujmE1Yb4jpL3RticBDdCOIir1Jxy1f4I2wrw82F4p/pM+yGdV1eloy6RjN7hNad0iq6CygcK8+Dbp7XHwmK1if8k/42wIZmWEsIBXKnmlCv2R9hHRNUAAIPABpxQcwogfTWseAIUjeHxvCxYPkj7uBA2IsGNEHam1qiZtWuW0dw3umOzd81GrXHMughX64+wD7VGYdZPfxp9TPebn/p9OmqNA8oLatSQkozxelPXj6WM17YTwgYkuBHCzlyt5pSr9UfYh0vVnMrcAXmnymmgQN5JbTshbECCGyHszNVqTrlaf4R9uFTNqcumg2mr2glRAQluhLAzV6s55Wr9EfbhUjWnqkbZtp0QFZDgRgg709WcKl2SQUeFiuiQaIfVnHK1/gj70NWcMrXhW4V215RDak7Fd9TuiiqvN7pt4ULYgAQ3QtiZq9WccrX+CPuoqOaUggNrTvn4ard7m+wN0HOW5LsRNiPBjRAOUFHNqa5xXUnNTmXN0TWkZqfafaeS1MDyDqZqTgHER4TQ+YZIfj1yjlX7TvLrkXP23TnVtB/0/xzCjOTWafmo5LkRNqVSFMUB+wBdR15eHuHh4eTm5hIWFubs7ggvYywj8MYTG52WTE8yFHsHtUZhV8Z5ci4V4KtS8fK3+8krKKZKgC9Xrv0XSDskuZ9Grd0Vdfk0nNwNOxdArcYwcqe2wKYQJljy+S3BjRBOpEumVzrnjG56SEZRhD3MXHOID7ccLXNcF1oseDzRMdmLC3LhzcZQlA9Df4a67e1/TeG2LPn8lmkpIZxEkukJZ1BrFFb/bjznjMOT+wWFw033ab/fs9j+1xNeQ4IbIZxEkukJZ3Cp5H4AiYO1fx78Fq5edMw1hceT4EYIJ5FkesIZXCq5H0BcO+2am+KrsP9/jrmm8HgS3AjhJOYmyTtXcM5hu6h01Bq1Q3dvCccxN2nf2UuFjtlFpVJB6yHa7399H/74H2RslTpTolL8nN0BIbyVLpleTn6O0XU3AD4qH15PfV3/syN2Ua3PXO+03VvC/nTJ/bJzC0y868BHBa/9eEj/s913UQWFa/+8kAHfPKn9PixWmxtHtogLK8jIjRBOUl4yPR2NojH4OSc/h6RNSazPXG+XPul2b5VeC2Tv6wrHqSi5H0DpgZrs3AKeWZJGyoEs23cofTV8N7Ls8bwsWD5I+7gQFpLgRggnMpVMz0dl/H9Ne+6ikt1b3sNUcj9TwY7ddlFp1JCSXOIKRq6aMl6mqITFZFpKCCfrFt+NrnFd9cn0zhWcM5iKKq3kLqq20W1t1g9Ldm/Z8rrCOXo2i+GuptH65H5nLxUaTEWVVnIXVYcGEbbpROYOyDO+LV1/1byT2nYJnWxzTeEVJLgRwgX4+vjqA4Y1R9eY9Rxb76KS3Vvex9dHpQ9UVu07adZzbLqL6rLpYNqqdkJcJ9NSQrgYc3dRmdvO1a8rXIO5u6jMbWeWqlG2bSfEdRLcCOFidLuoTC0yVqEiKjgKtUZt063a5lw3OiSaxMjESl9LuB7dLipT625UQHRYIBpFsd0W8fiO2l1R5V01rLa2nRAWkNpSQrgg3a4lwGCBrwoVCgrhgeHkFubqj9tqq3Z51wWpdeXpUg5k8cwSbUZsYx8M1UL8uZhfpP/ZJlvE01drd0UZvapKW0lctoMLpLaUEG7P1C6q8ABtPpCSgQ3Ybqu2qetGhURJYOMFTO2i0ikZ2ICNtog37acNYMKMBEiNuktgI6wiIzdCuDC1Rq3fRRURHMHEbRNN7mhSoSIqJIqUB1Lw9fG12XVrhdQiMTKx0ucU7kOtUfS7qGpWCeTpJXu4XFhstK0KiA4PYlvyHfj6mJpeMoNGrd0Vdfk05P4L66dAQCgkpUOQ/F0tLPv8lt1SQriwkruoUrNTHbZVu+R1hfcpuYvq1yPnTAY2YMMt4j6+/233VhTY9yWc/Uv75y3PWH9e4ZVkWkoINyFbtYUzOKXQpkoF7Z/Wfv/bh5LET1hMghsh3IRs1RbO4JQt4gAtHtHWnLqQAX//bNtzC48nwY0QbsIVtmpLtXDvY84W8ZjwINol1LDthQOqQOJg7fcbZ8L+FVItXJhN1twI4SZ0hTaTNiXpt4Tr6AKe5HbJdlv4K9XCvZOu0OYzS9JQYXyL+JS+TSu3mNiUGgnaP7N/h5XDtN9LtXBhBhm5EcKNVLRVu2tcV7uMrEi1cO9W3hbxTjfU5K6m0fx65JztkvuBNv/ND0llj0u1cGEG2QouhBsytlV744mNdhlZUWvU9FjZwyFb0IVrK7lFPCevkBlrtIU2q4f4c8GWyf00apjXrJyimirtCM6Y/dpdVsIrSBI/ITycbqt27/q9aRvdlo0nNtptZMWSauHCs+m2iN/TsjbDb69P18baxesXbJ3cz5Jq4UIYIcGNEG5OrVEza9csgzU4Orpjs3fNtnqKSragC2PUGoVDp/KMPqZ7J079Pt26KSqpFi4qSYIbIdycvUdWZAu6MGZXxnmy8wpNPl4yuZ/FpFq4qCQJboRwc/YeWXGFLejC9dg1uZ9UCxeVJMGNEG7O3iMrui3oQJkAxxFb0IVrsmtyPx9f7XZvwHiAo0DPWbKYWJgkwY0Qbs4RIytSLVyUZvfkfuVVC/cL/q8OlRBGyFZwITyALg8NYDS5n60CEKkWLkpKOZDFM0u0a7lKf5CogAWPJ1q/HVynZLXwKpHwUzKcSYfbx8EdEyt3buFWLPn8luBGCA9hLINwdEg0ye2S7T6yIkGP90o5kMXU79PJyjVcW/PErfWY0vcm218wfZU2iZ9/VXjgYyjK1y4sju8o01QeToKbckhwIzyZqSDDnsGHlGUQJZP7bf/nLMt3/0vNqgG8/sDNXCosJjJUOz1lkxINGg28fTPknjA8LmUZPJ4EN+WQ4EZ4G3sGH7rpsNI5dmw9HSbcR2GxmttmbeDM5WsGxyudtVgnfTUsH2jkgeuBU//PJcDxUJKhWAgB2LcmlL2TBwr3tPHPnDKBDdggazFo19+kJJt48Pr7MGW8VA4XEtwI4ansHXxIWQZRmlqjMPX7dKOPVTprMUhZBmE2CW6E8FD2Dj6kLIMobVfG+TILi0uqVNZikLIMwmwS3AjhoewdfEhZBlGaXbMWg5RlEGaT4EYID2Xv4EPKMojS7Jq1GKQsgzCb04Ob+fPnk5CQQFBQEK1bt2br1q0m237zzTfcdddd1KpVi7CwMDp06MDatWsd2Fsh3Ie9gw8pyyBKqyhrMVQya7GUZRBmcmpws2zZMsaMGcPEiRPZu3cvnTp1olevXhw/ftxo+y1btnDXXXexZs0a9uzZQ9euXenbty979+51cM+FcH2OCD6kLIMoyddHxZS+TQHTYytT+jatXL6b8soyBFSFerdZf27hMZya56Z9+/YkJiayYMEC/bEmTZpw7733MnPmTLPOcdNNNzFgwAAmT55sVnvJcyO8jSMyFzsjeaBwXaayFgOsHnUrN9epVvmLlCzLEBIBP42Hs39C4mBo/pD2uGQu9ihukcTv2rVrhISE8L///Y/77rtPf/z5559n3759bN68ucJzaDQa6tWrx7hx4xg1apTRNoWFhRQWFup/zsvLIy4uToIb4VWcEWRI5mLvVjJrcWRoEMtSj/PdvlO0rVed5U93QKWyQbbiko5tg8V9yh6XzMUew5Lgxs9BfSrj7NmzqNVqoqIMV7VHRUWRnZ1t1jnefPNNrly5Qv/+/U22mTlzJlOnTq1UX4Vwd74+vrSNblvmuL2CHlOZi3XJA2XKyvP5+qjo0CBC/3O9miGkHMwm9dgF5q3/m/q1qti2LEO+ie3leVnaWlSSudirOC240SkdvSuKYlZE//XXX/Pqq6+yatUqIiMjTbabMGECSUlJ+p91IzdCeDt7jaxUlDxQhYrZu2bTNa6rTFF5kZjwYO5sHMWP+7N4+5e/Sxy3QVmGCjMXq7SZixv3kSkqL+G0BcU1a9bE19e3zChNTk5OmdGc0pYtW8awYcNYvnw53bqV/5dwYGAgYWFhBl9CeDt7lmWQzMXCmJQDWazZX7b0gk3KMkjmYlGK04KbgIAAWrduzbp16wyOr1u3jo4dTeco+PrrrxkyZAhfffUVffoYmV8VQpTL3mUZJHOxKE1XlsHYAk+blGWQzMWiFKduBU9KSuKTTz5h4cKFHDp0iLFjx3L8+HFGjBgBaKeUBg0apG//9ddfM2jQIN58801uueUWsrOzyc7OJjc311m3IITbsffIimQuFqXZvSyDZC4WpTg1uBkwYADz5s1j2rRptGzZki1btrBmzRri4+MByMrKMsh58+GHH1JcXMyzzz5LTEyM/uv555931i0I4XbsPbIimYtFaXYvy1Bh5mIkc7GXcfqC4pEjRzJy5Eijjy1evNjg502bNtm/Q0J4OHuPrOiSByZtSkKFymD6SxfwvNT2Jcl/40XsXpZBl7l4+SC0AY6R6a2uL/+XF0fy33g8pwc3QgjH0o2s5OTnGF13o0JFVEhUpUZWdJmLje3G6pXQi9dTX5f8N15EV5YhO7fA6LobqGRZBvgvc3FKsuHiYh8/0BTDj0lQ/F/OM8l/49mcmqHYGSRDsRD/7ZYCjI6s2CoPTek8OhcKLvDi5hfLBFW2vq5wPSkHsnhmiXYdl7EPnTkP3sxDbWyQpqNk5uKqUXBqL6ybZKTh9SksyX/jNtwiQ7GzSHAjhJYjyjKUpNao6bGyh8nFzLoRo5QHUmSKykMZK8vg56OiWKPwSLu6zLy/uW0vqFHDvGblbBNXaUdwxuyXKSo34BYZioUQztUtvhtd47o6rCaUJbu0jGVTFu6vZ7MY7moabVCWQaWChz/ayde7jtMsNoyqQX62y1xsSf6bhE6Vu5ZwKRLcCOHFjJVlsFfmYsl/I6BsWQbQrsnZlXGeid8d0B+zSeZiyX/jtZy6FVwI4VrsmblY8t8IY1IOZBnNb2OTzMWS/8ZrSXAjhADsn7m4ovw3ANUDq3P6ymlSs1Otvo5wH7rMxcbYJHOxOflvQmNA0cD+FZCxVbtOR7g9CW6EEID9Mxfr8t8AJgOcC4UXmLBtAkPXDqXHyh6VGikSrs/umYt1+W8AkwHOlbPweT9YOQw+u1u7ADl9tXXXEy5DghshBOCYNTG6/DeRIZEVtrXFVJhwbXbPXAz/5b8JK7V2JyBU+6emyPB4XpY2GaAEOG5NFhQLIQDHrYkpuUvr9JXTvJ76OhcKL5Rpp6CgQsXsXbPpGtdVtod7ILtnLtZp2g8a9/kv/01ITVj1DFy7ZKSxAqggZbz2OfK+c0syciOEABxbE0q3SyuqSpTRwEanslNhwrXpMheXt+G70pmLdXx8tdu9mz+o/d7cLeLCLUlwI4QAyl8TU7om1Jqja2yy6NfcKa6dp3ba7JrCdfj6qJjStylgeslvn+bavDir9p3k1yPnrF9cXJK5W78zNstCYzclGYqFEAZMZS7uldCLNRlrbJr/JjU7laFrh1r0HKlD5XmMZS6uGujL5UI1KhWU/JSySf6bjK3axcOWkFpUTiflF8ohwY0QFXNUTShdSQZTRTyNkTpUnkmtUQwyF+dcKuD5pfvKtNON8Cx4PNH6AEdfliEL45WujJFaVM4mwU05JLgRwjL2rgllqohneVSoiAyOZPpt0zlfcN5mJSKEa1BrFG6bvcHkNnEVEB0exLbkO6wv0ZC+WrsrCrAowAmNgfs+gCtntMn/4jvKomMHkeCmHBLcCGEZc6eOFvZYaHVNKGNTYZaS6SrP8euRczzy8c4K2309/JYypRwskr4aUpIrWFxcAZmuchgpnCmEsBlH5b8pWcTzSO4RPvrjI4vOocuLI9NV7s8h+W+g7BbxnD9h6xzLzqHLiyPTVS5FghshRLkclf+mZBHP1OxUi4MbXV6cWb/Noqp/VZmucmMOy38D/20RB+1CY0uDG11enJ+SIShcpqtchAQ3Qohy6fLfmFr0q1tzY4v8N+Ze0xQFhdNXTzN83XD9MZmucj+6/DfZuQUmf/s2y39Tkq4WlUULjdG2vXRKW8ZBR6arnEry3AghyuWM/Dfm1KEyl2666udjP5OanSr5ctyAOflv7k+sbfv8N+bUojKXbrrqwHfaESHJl+NQsqBYCGEWR+a/Ke+a1vJR+aBRNPqfZUTH9RnLfxPs78vVIjUqDMdWbJL/RscWC411VD7aquM6MqJjNdktVQ4JboSwnqPy35i6ZkRwBBO3TbR4usoYXR/f6PwG1YOq6+9J1ui4FofmvylJoy5bi8ri6Spjrvf0wcVQJUJ7flmjYxYJbsohwY0QtmHv/DemWJMXpzymRnRK7t6SoMc1OCT/jSlW5cUph6kRnZK7tyToMSDBTTkkuBHCNhyR/8YUW05XlaZChYJCeGA4uYW5+uMS9Difw/LfmGLL6aoyrk+0BdeAq+f/OyxBj57kuRFC2J0lRS9tHQiUzotjy+kq3fNLBjagXZg8dtNYi4Oe0lN5EgxZz9y8Ntv/OaOfxmqXUMN2ozil8+LYdLrq+vNLBjZwfWHyQMuDnpLTal4YDMnIjRDCKq5W9NLW01XmKm+kp3dCb5OLrS0NhiRIMn/kpiSbLjQ2xtbTVWYrZ6Sn2YNwYIXhCJO1wZALBUkyLVUOCW6EsA1XLHppbLqq9JoaZ7MmGLJlkOTOdGtuyst/U5rNFxobY2y6qvSaGqezIhiyZZBkAxLclEOCGyFsx9qil/ZYaKxjakeXJX10B9aOGLn71veUA1k8syQNsKyet90WGuuU/lDPPwf/G3L9Qc9531k9YmSDre8S3JRDghshbMvaxb32WGhsijuM6NibvUfNHMlY/htz2G2hsSluMaJjb9eDSRvU3pLgphwS3AhheyVHS8wtevlU86doUK2Bw6ZMvGVEpzz2HjVzpJL5b/4+fZn3Nv5T4XNGdW1Ao6hQ2y80Lo/XjOiUR6UdwRmzv1JTVBLclEOCGyHsy9UWGpfH2IhOtYBqXLx2UT/t44kcOWrmCC650Lg8xkZ09NM8pXMve5DBP/xXpNQKshVcCOE01hS91NV/cvSUSekt5bpRpI0nNnp00GPuNn53YU6hzdKycwt4ZkmafRcam1J6S7lu4e2fP3p20HPZ9nmpTJGRGyGEzVm7Lbt6YHXGtR1HVJUop+/uMbbbyFOCHk8buQHrFxpHhQXyZv+WnL1c6NjpKlOM7TbylKDHgSM3EtwIIeyislmEXXV3j7lBj6mios4MhjxpzY0x1i40Lsmp01XlMTfoCasNzR4ou2vJqcGQrLmxOwluhHAcaxYa67jb7h5Lku9ZEgzZKkhyt9fTWtYsNC7JIXlxbMmS5HuWBEM2C5Jkt5RDSHAjhHNYs9BYhYrI4Eim3zad8wXnPSYZHVgWDNkqSEpul+zRgU1p1iw0BhedrrIVSzMR2yJI6jlL8tzYmwQ3QjiHNRmNjZECloakXINp1mQ0NkU3XXVX02j9yJBHBT2WckK5BgluyiHBjRDOY4v6TxVV7famkQlRMWsWGhujm4SpFuLPxfwi/XGXXaPjgSS4KYcEN0I4V2UXGpuiW1PyRuc3qB5U3atHLIQhWyw0NkU3ZvP+o62oXiVQRnTsSIKbckhwI4Tz6aZMTl85zeupr3Ox8KLNdg6VLqvgjQUmRVklFxrXrBLIC//7ndN5lZ+u0vFRgabEySqaxirZHwmGzCPBTTkkuBHCtdhiqqo81haYlGDIs9lqusqU8qax+rWIYfXvWQYjSRIMVUyCm3JIcCOE67HXVJU1HBUMyUJg57PndJWlHBUMWXrclUhwUw4JboRwTSU/1COCI5i4bWKld1Y5gjXBkKXHbRk8CUP2nq6yF2uCIUuP2zJ4sgUJbsohwY0Q7sHe01XuwpbBk+wmq5i9p6vchS2DJ1vtJpPgphwS3AjhPry1arc9eEuGYlswNl2l+5B3o0pOLsGWGZ8luCmHBDdCuBdzM/OW3iUlyvL02lK2ZGx6ZV16dpmgp/QuKVGWCogOD2Jb8h2VmqKS4KYcEtwI4RlKBz0XCi7w4uYXAe+exjKHJ1YFd5TSQc+FK9d49iuZxjLH18NvoUODCKufb8nnt5/VVxFCCCfy9fEt8wE9VzVXprHMcCb/jLO74LZ8fVRlPqAX+CTKNJYZci45bleaBDdCCI/RLb6b0V1FlhSY9IZgqFZILWd3waP0bBZjdFeRsWksUwtvvSEYigwNcti1ZFpKCOEV7FVt252CIVlz43iWbJn21GBI1tw4gAQ3Qghz2CsYsvS4rYIn2S3lHuwVDFl63FbBk+yWchAJboQQ9mCrTMT2DJ6S2yVLYONhbJWJ2J7Bk+S5cQAJboQQ7kjKOAhncKUyDhLclEOCGyGEEML9WPL57eOgPgkhhBBCOITTg5v58+eTkJBAUFAQrVu3ZuvWreW237x5M61btyYoKIj69evzwQcfOKinQgghhHAHTg1uli1bxpgxY5g4cSJ79+6lU6dO9OrVi+PHjxttn5GRQe/evenUqRN79+7l5ZdfZvTo0axcudLBPRdCCCGEq3Lqmpv27duTmJjIggUL9MeaNGnCvffey8yZM8u0T05OZvXq1Rw6dEh/bMSIEfz+++/8+uuvZl1T1twIIYQQ7sct1txcu3aNPXv20L17d4Pj3bt3Z8eOHUaf8+uvv5Zp36NHD3bv3k1RUZHR5wghhBDCuzit/MLZs2dRq9VERUUZHI+KiiI7O9voc7Kzs422Ly4u5uzZs8TElN1HX1hYSGFhof7nvLw8G/ReCCGEEK7K6QuKVSrD/e+KopQ5VlF7Y8d1Zs6cSXh4uP4rLi6ukj0WQgghhCtzWnBTs2ZNfH19y4zS5OTklBmd0YmOjjba3s/Pj4gI42XUJ0yYQG5urv7rxIkTtrkBIYQQQrgkpwU3AQEBtG7dmnXr1hkcX7duHR07djT6nA4dOpRp//PPP9OmTRv8/f2NPicwMJCwsDCDLyGEEEJ4LqetuQFISkpi4MCBtGnThg4dOvDRRx9x/PhxRowYAWhHXU6ePMnnn38OaHdGvffeeyQlJTF8+HB+/fVXPv30U77++muzr6mbxpK1N0IIIYT70H1um7XJW3Gy999/X4mPj1cCAgKUxMREZfPmzfrHBg8erHTu3Nmg/aZNm5RWrVopAQEBSr169ZQFCxZYdL0TJ04oaIucypd8yZd8yZd8yZebfZ04caLCz3qvqy2l0Wg4deoUoaGh5S5cdoS8vDzi4uI4ceKEx0+Xecu9est9gvfcq7fcJ3jPvXrLfYJn3auiKFy6dInY2Fh8fMpfVePUaSln8PHxoU6dOs7uhgFvWgvkLffqLfcJ3nOv3nKf4D336i33CZ5zr+Hh4Wa1c/pWcCGEEEIIW5LgRgghhBAeRYIbJwoMDGTKlCkEBgY6uyt25y336i33Cd5zr95yn+A99+ot9wneda8led2CYiGEEEJ4Nhm5EUIIIYRHkeBGCCGEEB5FghshhBBCeBQJboQQQgjhUSS4cZL58+eTkJBAUFAQrVu3ZuvWrc7uUqXNnDmTtm3bEhoaSmRkJPfeey+HDx82aKMoCq+++iqxsbEEBwfTpUsXDh486KQe28bMmTNRqVSMGTNGf8yT7vPkyZM8/vjjREREEBISQsuWLdmzZ4/+cU+41+LiYl555RUSEhIIDg6mfv36TJs2DY1Go2/jrve5ZcsW+vbtS2xsLCqViu+++87gcXPuq7CwkOeee46aNWtSpUoV+vXrx7///uvAu6hYefdZVFREcnIyzZs3p0qVKsTGxjJo0CBOnTplcA53uE+o+Hda0tNPP41KpWLevHkGx93lXq0lwY0TLFu2jDFjxjBx4kT27t1Lp06d6NWrF8ePH3d21ypl8+bNPPvss+zcuZN169ZRXFxM9+7duXLlir7N66+/zty5c3nvvfdITU0lOjqau+66i0uXLjmx59ZLTU3lo48+4uabbzY47in3eeHCBW699Vb8/f356aefSE9P580336RatWr6Np5wr7Nnz+aDDz7gvffe49ChQ7z++uvMmTOHd999V9/GXe/zypUrtGjRgvfee8/o4+bc15gxY/j2229ZunQp27Zt4/Lly9x9992o1WpH3UaFyrvP/Px80tLSmDRpEmlpaXzzzTf89ddf9OvXz6CdO9wnVPw71fnuu+/47bffiI2NLfOYu9yr1SyqOilsol27dsqIESMMjjVu3FgZP368k3pkHzk5OQqgL4aq0WiU6OhoZdasWfo2BQUFSnh4uPLBBx84q5tWu3TpktKoUSNl3bp1SufOnZXnn39eURTPus/k5GTltttuM/m4p9xrnz59lKFDhxocu//++5XHH39cURTPuU9A+fbbb/U/m3NfFy9eVPz9/ZWlS5fq25w8eVLx8fFRUlJSHNZ3S5S+T2N27dqlAEpmZqaiKO55n4pi+l7//fdfpXbt2sqBAweU+Ph45a233tI/5q73agkZuXGwa9eusWfPHrp3725wvHv37uzYscNJvbKP3NxcAGrUqAFARkYG2dnZBvceGBhI586d3fLen332Wfr06UO3bt0MjnvSfa5evZo2bdrw0EMPERkZSatWrfj444/1j3vKvd5222388ssv/PXXXwD8/vvvbNu2jd69ewOec5+lmXNfe/bsoaioyKBNbGwszZo1c+t7z83NRaVS6UchPek+NRoNAwcO5KWXXuKmm24q87gn3aspXlc409nOnj2LWq0mKirK4HhUVBTZ2dlO6pXtKYpCUlISt912G82aNQPQ35+xe8/MzHR4Hytj6dKlpKWlkZqaWuYxT7rPo0ePsmDBApKSknj55ZfZtWsXo0ePJjAwkEGDBnnMvSYnJ5Obm0vjxo3x9fVFrVYzY8YMHnnkEcCzfqclmXNf2dnZBAQEUL169TJt3PXvrIKCAsaPH8+jjz6qLybpSfc5e/Zs/Pz8GD16tNHHPeleTZHgxklUKpXBz4qilDnmzkaNGsUff/zBtm3byjzm7vd+4sQJnn/+eX7++WeCgoJMtnP3+wTtvwDbtGnD//3f/wHQqlUrDh48yIIFCxg0aJC+nbvf67Jly1iyZAlfffUVN910E/v27WPMmDHExsYyePBgfTt3v09TrLkvd733oqIiHn74YTQaDfPnz6+wvbvd5549e3j77bdJS0uzuN/udq/lkWkpB6tZsya+vr5louOcnJwy/3pyV8899xyrV69m48aN1KlTR388OjoawO3vfc+ePeTk5NC6dWv8/Pzw8/Nj8+bNvPPOO/j5+envxd3vEyAmJoamTZsaHGvSpIl+8bun/E5feuklxo8fz8MPP0zz5s0ZOHAgY8eOZebMmYDn3Gdp5txXdHQ0165d48KFCybbuIuioiL69+9PRkYG69at04/agOfc59atW8nJyaFu3br6v58yMzN54YUXqFevHuA591oeCW4cLCAggNatW7Nu3TqD4+vWraNjx45O6pVtKIrCqFGj+Oabb9iwYQMJCQkGjyckJBAdHW1w79euXWPz5s1ude933nkn+/fvZ9++ffqvNm3a8Nhjj7Fv3z7q16/vEfcJcOutt5bZzv/XX38RHx8PeM7vND8/Hx8fw78OfX199VvBPeU+SzPnvlq3bo2/v79Bm6ysLA4cOOBW964LbP7++2/Wr19PRESEweOecp8DBw7kjz/+MPj7KTY2lpdeeom1a9cCnnOv5XLSQmavtnTpUsXf31/59NNPlfT0dGXMmDFKlSpVlGPHjjm7a5XyzDPPKOHh4cqmTZuUrKws/Vd+fr6+zaxZs5Tw8HDlm2++Ufbv36888sgjSkxMjJKXl+fEnldeyd1SiuI597lr1y7Fz89PmTFjhvL3338rX375pRISEqIsWbJE38YT7nXw4MFK7dq1lR9++EHJyMhQvvnmG6VmzZrKuHHj9G3c9T4vXbqk7N27V9m7d68CKHPnzlX27t2r3yVkzn2NGDFCqVOnjrJ+/XolLS1NueOOO5QWLVooxcXFzrqtMsq7z6KiIqVfv35KnTp1lH379hn8/VRYWKg/hzvcp6JU/DstrfRuKUVxn3u1lgQ3TvL+++8r8fHxSkBAgJKYmKjfLu3OAKNfixYt0rfRaDTKlClTlOjoaCUwMFC5/fbblf379zuv0zZSOrjxpPv8/vvvlWbNmimBgYFK48aNlY8++sjgcU+417y8POX5559X6tatqwQFBSn169dXJk6caPDB5673uXHjRqP/Xw4ePFhRFPPu6+rVq8qoUaOUGjVqKMHBwcrdd9+tHD9+3Al3Y1p595mRkWHy76eNGzfqz+EO96koFf9OSzMW3LjLvVpLpSiK4ogRIiGEEEIIR5A1N0IIIYTwKBLcCCGEEMKjSHAjhBBCCI8iwY0QQgghPIoEN0IIIYTwKBLcCCGEEMKjSHAjhBBCCI8iwY0Qwq28+uqrtGzZ0tndEEK4MEniJ4RwGRVVJB48eDDvvfcehYWFZWoDCSGEjgQ3QgiXUbI69bJly5g8ebJB4c7g4GDCw8Od0TUhhBuRaSkhhMuIjo7Wf4WHh6NSqcocKz0tNWTIEO69917+7//+j6ioKKpVq8bUqVMpLi7mpZdeokaNGtSpU4eFCxcaXOvkyZMMGDCA6tWrExERwT333MOxY8cce8NCCLuQ4EYI4fY2bNjAqVOn2LJlC3PnzuXVV1/l7rvvpnr16vz222+MGDGCESNGcOLECQDy8/Pp2rUrVatWZcuWLWzbto2qVavSs2dPrl275uS7EUJUlgQ3Qgi3V6NGDd555x1uvPFGhg4dyo033kh+fj4vv/wyjRo1YsKECQQEBLB9+3YAli5dio+PD5988gnNmzenSZMmLFq0iOPHj7Np0ybn3owQotL8nN0BIYSorJtuugkfn//+rRYVFUWzZs30P/v6+hIREUFOTg4Ae/bs4Z9//iE0NNTgPAUFBRw5csQxnRZC2I0EN0IIt+fv72/ws0qlMnpMo9EAoNFoaN26NV9++WWZc9WqVct+HRVCOIQEN0IIr5OYmMiyZcuIjIwkLCzM2d0RQtiYrLkRQnidxx57jJo1a3LPPfewdetWMjIy2Lx5M88//zz//vuvs7snhKgkCW6EEF4nJCSELVu2ULduXe6//36aNGnC0KFDuXr1qozkCOEBJImfEEIIITyKjNwIIYQQwqNIcCOEEEIIjyLBjRBCCCE8igQ3QgghhPAoEtwIIYQQwqNIcCOEEEIIjyLBjRBCCCE8igQ3QgghhPAoEtwIIYQQwqNIcCOEEEIIjyLBjRBCCCE8igQ3QgghhPAo/w8z3PPE656OBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming 'predictions' contains the output from your model for the test set\n",
    "\n",
    "for i, batch in enumerate(test_loader_synthetic):\n",
    "  if i == 0:\n",
    "    # Access the data in the batch (assuming it's in the format [data, labels])\n",
    "    data = batch[0]\n",
    "    data = pd.DataFrame(data)\n",
    "    data_v = data[data['fid'] == 1]\n",
    "    data_r = data[data['fid'] == 2]\n",
    "    # Assuming your data has 'time' and 'obs_flux' attributes\n",
    "    time_v = data_v['mjd']\n",
    "    time_r = data_r['mjd']\n",
    "    obs_flux_r = data_r['flux']\n",
    "    obs_flux_v = data_v['flux']\n",
    "\n",
    "    # Plot the data from the test loader\n",
    "    plt.plot(time_v, obs_flux_v, '-o', label='Test Data V')\n",
    "    plt.plot(time_r, obs_flux_r, '-o', label='Test Data R')\n",
    "\n",
    "# Plot the predictions\n",
    "plt.plot(predictions[0]['time'][0], predictions[0]['obs_flux'][0], 'o', label='Predictions')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Observed Flux')\n",
    "plt.title('Test Data vs. Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(num_epoch), np.array(train_losses)/300)\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Train loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(time, original_magnitude, reconstructed_magnitude, title='Curvas Originales y Reconstruidas'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time, original_magnitude, label='Original', linestyle='--', color='blue')\n",
    "    plt.plot(time, reconstructed_magnitude, label='Reconstruido', linestyle='-', color='red')\n",
    "    plt.xlabel('Tiempo')\n",
    "    plt.ylabel('Magnitud')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Definir una lista para almacenar las pÃ©rdidas de cada muestra de prueba\n",
    "test_losses = []\n",
    "\n",
    "# Definir una lista para almacenar las reconstrucciones de las muestras de prueba\n",
    "reconstructions = []\n",
    "\n",
    "#with torch.inference_mode():\n",
    "with torch.inference_mode():\n",
    "    for _, group_oid in test_data_synthetic.groupby(by='oid'):\n",
    "        X = group_oid[['mjd','magpsf','sigmapsf']]\n",
    "        #X = process_light_curve_atat(X)# Karpathy constant is just a joke\n",
    "        X = process_light_curve_parsnip(X)\n",
    "        X, X_weights = create_grid(X)\n",
    "        time = X[0,:]\n",
    "        original_magnitude = X[1,:]\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        X_weights = torch.tensor(X_weights, dtype=torch.float32)\n",
    "        X = X.T\n",
    "        X_weights = X_weights.T\n",
    "\n",
    "        # Forward pass\n",
    "        X_reconstructed, mu, logvar = model(X)\n",
    "\n",
    "        #print(X_reconstructed)\n",
    "        # Convierte las predicciones a numpy\n",
    "        reconstructed_magnitude = X_reconstructed.cpu().numpy()[:,0]  # Segunda fila para magnitud\n",
    "        #print(len(reconstructed_magnitude))\n",
    "        \n",
    "        # Grafica\n",
    "        plot_curves(time, original_magnitude, reconstructed_magnitude, title=f'Curvas para OID {oid}')\n",
    "        \n",
    "        # Sal de la iteraciÃ³n si solo deseas graficar para un OID\n",
    "        break\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(X_reconstructed, X_weights, mu, logvar)\n",
    "        #replace_nan_grads(model.parameters())\n",
    "\n",
    "        # Guardar la pÃ©rdida y las reconstrucciones\n",
    "        test_losses.append(loss.item())\n",
    "        reconstructions.append(X_reconstructed.cpu().numpy())\n",
    "\n",
    "    # Calcular la pÃ©rdida promedio en los datos de prueba\n",
    "    average_test_loss = np.mean(test_losses)\n",
    "    print(\"Average test loss:\", average_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = np.array(reconstructions)\n",
    "len(reconstructions[0][:,0]), len(reconstructions[0][:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 2\n",
    "sample_data = test_data_synthetic[test_data_synthetic.oid == test_data_synthetic.oid.unique()[sample_index]]\n",
    "sample_data = process_light_curve_parsnip(sample_data)\n",
    "sample_data, _ = create_grid(sample_data)\n",
    "sample_reconstruction = reconstructions[sample_index]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(sample_data[0,:], sample_data[1,:], 'o', color='C0')\n",
    "ax.plot(np.linspace(0,300,300), sample_reconstruction[:,1], 'o', color='C1')\n",
    "\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Flux')\n",
    "ax.set_title('Original vs. Reconstructed Flux')\n",
    "#ax.legend()\n",
    "#ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
